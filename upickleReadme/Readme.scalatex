@import Main._


@def lnk(txt: String, url: String) = a(txt, href:=url)
@val exampleTests = wd/'upickle/'shared/'src/'test/'scala/'example/"ExampleTests.scala"
@val macroTests = wd/'upickle/'shared/'src/'test/'scala/'upickle/"MacroTests.scala"

@val optionsAsNullTests = wd/'upickle/'shared/'src/'test/'scala/'example/"OptionsAsNullTests.scala"

@val autoPickleTests = wd/'upickle/'shared/'src/'test/'scala/'upickle/"AutoPickleTests.scala"


@a(
  href := "https://github.com/lihaoyi/upickle-pprint",
  img(
    position.absolute,
    top := 0,
    right := 0,
    border := 0,
    src := "https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67",
    alt := "Fork me on GitHub",
    data.`canonical-src` := "https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
  )
)


@sect("ÂµPickle "+ _root_.upickle.Constants.version)

  @p
    uPickle (pronounced micro-pickle) is a lightweight serialization library for Scala. It's key features are:
  @ul
    @li
      Less than 1000 lines of code
    @li
      Zero-reflection 100% static serialization and deserialization
    @li
      @sect.ref("Getting Started", "Human-readable JSON encoding"), with a fast @sect.ref{JSON API}
    @li
      @sect.ref("Supported Types", "A large, well-defined set of supported types, with well-defined semantics")
    @li
      Handling of @sect.ref("Defaults", "default values") and @sect.ref("Custom Keys", "custom keys"), for maintaining backwards compatiblity while schemas change
    @li
      Minimal dependencies: Only depends on @lnk("Jawn", "https://github.com/non/jawn") on the JVM, and on the Javascript standard library in Scala.js
    @li
      Works in @sect.ref("ScalaJS"), allowing transfer of structured data between the JVM and Javascript

  @sect{Getting Started}
    @p
      Add the following to your SBT config:
    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "upickle" % "@_root_.upickle.Constants.version"


    @p
      And then you can immediately start writing and reading common Scala objects to strings:

    @hl.ref(exampleTests, Seq("'simple", ""))

    @sect{ScalaJS}
      @p
        For ScalaJS applications, use this dependencies instead:
      @hl.scala
        libraryDependencies += "com.lihaoyi" %%% "upickle" % "@_root_.upickle.Constants.version"
      @p

        Other than that, everything is used the same way. upickle-0.5.0 is only compatible with ScalaJS 0.6.x.

    @sect{Scala 2.10}
      @p

        uPickle 0.5.x does not support Scala 2.10; only 2.11 and 2.12 are supported

  @sect{Supported Types}
    @p
      Out of the box, uPickle supports writing and reading the following types:
    @ul
      @li
        @hl.scala{Boolean}, @code{Byte}, @code{Char}, @code{Short}, @code{Int}, @code{Long}, @code{Float}, @code{Double}
      @li
        @code{Tuple}s from 1 to 22
      @li
        Immutable @code{Seq}, @code{List}, @code{Vector}, @code{Set}, @code{SortedSet}, @code{Option}, @code{Array}, @code{Map}s, and all other collections with a reasonable @hl.scala{CanBuildFrom} implementation
      @li
        @code{Duration}, @code{Either}
      @li
        Stand-alone @hl.scala{case class}es and @hl.scala{case object}s, and their generic equivalents,
      @li
        Non-generic @hl.scala{case class}es and @hl.scala{case object}s that are part of a @hl.scala{sealed trait} or @hl.scala{sealed class} hierarchy
      @li
        @hl.scala{sealed trait} and @hl.scala{sealed class}es themselves, assuming that all subclasses are picklable
      @li
        @code{UUID}s
      @li
        @hl.scala{null}
    @p
      Readability/writability is recursive: a container such as a @code{Tuple} or @hl.scala{case class} is only readable if all its contents are readable, and only writable if all its contents are writable. That means that you cannot serialize a @hl.scala{List[Any]}, since uPickle doesn't provide a generic way of serializing @code{Any}. Case classes are only serializable up to 22 fields.

    @p
      Case classes are serialized using the @hl.scala{apply} and @hl.scala{unapply} methods on their companion objects. This means that you can make your own classes serializable by giving them companions @hl.scala{apply} and @hl.scala{unapply}. @hl.scala{sealed} hierarchies are serialized as tagged unions: whatever the serialization of the actual object, together with the fully-qualified name of its class, so the correct class in the sealed hierarchy can be reconstituted later.

    @p
      That concludes the list of supported types. Anything else is not supported.

  @sect{Default Picklers}


    @p
      This is a non-comprehensive list of what the most commonly-used types pickle to using uPickle. To begin, let's import upickle

    @hl.scala
      import upickle.default._

    @p
      Booleans are serialized as JSON booleans

    @hl.ref(exampleTests, Seq("'more", "'booleans", ""))

    @p
      Numbers are serialized as JSON numbers

    @hl.ref(exampleTests, Seq("'more", "'numbers", ""))

    @p
      Except for @hl.scala{Long}s, which too large for Javascript. These are serialized as JSON Strings, keeping the interchange format compatible with the browser's own JSON parser, which provides the best performance in Scala.js

    @hl.ref(exampleTests, Seq("'more", "'longs", ""))

    @p
      Special values of @hl.scala{Double}s and @hl.scala{Float}s are also serialized as Strings

    @hl.ref(exampleTests, Seq("'more", "'specialNumbers", ""))



    @p
      Both @hl.scala{Char}s and @hl.scala{String}s are serialized as Strings

    @hl.ref(exampleTests, Seq("'more", "'charStrings", ""))

    @p
      @code{Array}s and most immutable collections are serialized as JSON lists

    @hl.ref(exampleTests, Seq("'more", "'seqs", ""))

    @p
      @code{Option}s are serialized as JSON lists with 0 or 1 element

    @hl.ref(exampleTests, Seq("'more", "'options", ""))


    @p
      Tuples of all sizes (1-22) are serialized as heterogenous JSON lists

    @hl.ref(exampleTests, Seq("'more", "'tuples", ""))

    @p
      Case classes of sizes 1-22 are serialized as JSON dictionaries with the keys being the names of each field.
      To begin with, you need to define a serializer in the Case Class's companion object:

    @hl.scala
      import upickle.default.{ReadWriter => RW, macroRW}

    @p
      After that, you can begin serializing that case class.

    @hl.ref(exampleTests, Seq("object Simple", ""))
    @hl.ref(exampleTests, Seq("'more", "'caseClass", ""), "  }")

    @p
      Sealed hierarchies are serialized as tagged values, the serialized object tagged with the full name of the instance's class:

    @hl.ref(exampleTests, Seq("object Sealed", ""))
    @hl.ref(exampleTests, Seq("'more", "'sealed", ""), "  }")

    @p
      Serializability is recursive; you can serialize a type only if all its members are serializable. That means that collections, tuples and case-classes made only of serializable members are themselves serializable

    @hl.ref(exampleTests, Seq("object Recursive", ""))
    @hl.ref(exampleTests, Seq("'more", "'recursive", ""), "  }")

    @p

      Nulls serialize into JSON nulls, as you would expect

    @hl.ref(exampleTests, Seq("'more", "'null", ""), "  }")

    @p

      uPickle only throws exceptions on unpickling; if a pickler is properly defined, serializing a data structure to a @hl.scala{String} should never throw an exception.
    @p
      On unpickling, uPickle throws one of two subclasses of @code{upickle.Invalid}:
    @ul
      @li
        @code{upickle.Invalid.Json}: thrown when unpickling fails at the first step which attempst to convert the incoming @code{String} into semi-structured JSON data. The exception contains data about where parsing failed (@code{input}, @code{line}, @code{col}) as well as a human-readable error message.
      @li
        @code{upickle.Invalid.Data}: thrown when unpickling fails at the second step which attempts to convert the parsed JSON tree into structured data of the desired type. Contains the offending JSON subtree in @code{data}, along with a human-readable error message.

  @sect{Manual Sealed Trait Picklers}
    @p
      Due to a bug in the Scala compiler SI-7046, automatic sealed trait
      pickling can fail unpredictably. This can be worked around by instead
      using the @code{macroRW} and @code{merge} methods to manually specify
      which sub-types of a sealed trait to consider when pickling:

    @hl.ref(macroTests, "sealed trait TypedFoo", "// End TypedFoo")

  @sect{Defaults}

    @p
      If a field is missing upon deserialization, uPickle uses the default value if one exists

    @hl.ref(exampleTests, Seq("'defaults", "'reading"), "  }")

    @p

      If a field at serialization time has the same value as the default, uPickle leaves it out of the serialized blob

    @hl.ref(exampleTests, Seq("'defaults", "'writing"), "  }")

    @p

      This allows you to make schema changes gradually, assuming you have already pickled some data and want to add new fields to the case classes you pickled. Simply give the new fields a default value (e.g. @hl.scala{""} for Strings, or wrap it in an @hl.scala{Option[T]} and make the default @hl.scala{None}) and uPickle will happily read the old data, filling in the missing field using the default value.

  @sect{Custom Keys}
    @p

      uPickle allows you to specify the key that a field is serialized with via a @hl.scala{@@key} annotation


    @hl.ref(exampleTests, Seq("object Keyed", ""))
    @hl.ref(exampleTests, Seq("'keyed", "'attrs", ""))

    @p

      Practically, this is useful if you want to rename the field within your Scala code while still maintaining backwards compatibility with previously-pickled objects. Simple rename the field and add a @hl.scala{@@key("...")} with the old name so uPickle can continue to work with the old objects correctly.
    @p
      You can also use @hl.scala{@@key} to change the name used when pickling the case class itself. Normally case classes are pickled without their name, but an exception is made for members of sealed hierarchies which are tagged with their fully-qualified name. uPickle allows you to use @hl.scala{@@key} to override what the class is tagged with:

    @hl.ref(exampleTests, Seq("object KeyedTag", ""))
    @hl.ref(exampleTests, Seq("'keyed", "'tag", ""))



    @p
      This is useful in cases where:
    @ul
      @li
        you wish to rename the class within your Scala code, or move it to a different package, but want to preserve backwards compatibility with previously pickled instances of that class
      @li
        you try to tackle the resource issue (bandwidth, storage, CPU) because FQNs might get quite long

  @sect{Custom Picklers}


    @p
      Apart from customizing the keys used to store the fields of a class, uPickle also allows you to completely replace the default @code{Reader}/@code{Writer} used to write that class. For classes you control. You need to provide an implicit @code{Reader}/@code{Writer} pair in the companion object:

    @hl.ref(exampleTests, Seq("object Custom2", ""))

    @p
      In this example, instead of pickling to a normal @code{Js.Obj}, we pickle to a @code{Js.Str}, storing both @code{i} and @code{s} as part of that single string.

    @p
      Note that when writing custom picklers, it is entirely up to you to get it right, e.g. making sure that an object that gets round-trip pickled/unpickled comes out the same as when it started.

  @sect{Custom Configuration}
    @p
      Often, there will be times that you want to customize something on a project-wide level. uPickle provides hooks in letting you subclass the @hl.scala{upickle.Api} trait to create your own bundles apart from the in-built @hl.scala{upickle.default} and @hl.scala{upickle.legacy}. You have multiple levels of possible customization:

    @ul
      @li
        @hl.scala{upickle.Api}, which lets you customize the @hl.scala{annotate} methods, which are used to tag sealed hierarchies with their class names. This is used to e.g. distinguish @hl.scala{upickle.default}'s @hl.scala{$type} attribute vs @hl.scala{upickle.legacy}'s array-wrapper
      @li
        @hl.scala{upickle.AttributeTagged}, which assumes you want the standard @hl.scala{annotate} method using a type attribute, but letting you customize the attribute.
      @li
        In both these cases, you are also free to override the @hl.scala{CaseR} and @hl.scala{CaseW} implicits, which controls how case classes are serialized. For example, you could make it serialize to a JSON array rather than a dictionary. Or, for example, convert the @code{camelCase} Scala identifiers to @code{snake_case} or some other convention:

      @hl.ref(exampleTests, Seq("'snakeCase", ""))

    @p
      If you are using uPickle to convert JSON from another source into Scala data structures, you may find the following encoding of @hl.scala{Option[T]} more convenient than the defaults:

    @hl.ref(optionsAsNullTests, "object OptionPickler", "// end_ex")

    @p
      This custom configuration allows you to treat @hl.scala{null}s as @hl.scala{None}s and anything else as @hl.scala{Some(...)}s. Simply @hl.scala{import OptionPickler._} instead of the normal uPickle import throughout your project and you'll have the customized reading/writing available to you.
  @sect{Limitations}

    @p

      uPickle is a work in progress, and doesn't currently support:
    @ul
      @li
        Circular object graphs
      @li
        Reflective reading and writing
      @li
        Read/writing of untyped values e.g. @code{Any}
      @li
        Read/writing arbitrarily shaped objects
      @li
        Read/writing case classes with multiple parameter lists.
    @p
      Most of these limitations are inherent in the fact that ScalaJS does not support reflection, and are unlikely to ever go away. In general, uPickle is designed to serialize statically-typed, tree-shaped, immutable data structures. Anything more complex is out of scope.

  @sect{JSON API}

    @p

      Although uPickle's object read/writing API makes does not expose you to it, under the hood it uses a nice JSON serialization format. Despite being less-compact than binary formats, this allows for very-fast serializing and deserializing from Strings on both Scala-JVM (which has other alternatives) and ScalaJS, where JSON is really your only choice. The JSON API is minimal but nonetheless very convenient, and can be used directly.
    @p
      uPickle bundles two very-fast JSON parsers, which it uses for parsing strings into structured-trees, before then marshalling them into typed objects.
    @ul
      @li
        @lnk("Jawn", "https://github.com/non/jawn") on the JVM
      @li
        @lnk("JSON.parse", "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse") on Scala.js
    @p
      That makes uPickle's JSON library competitive with the highest performance JSON libraries both on the JVM (GSON, Jackson, etc.) as well as in Javascript.
    @p
      uPickle's JSON API is exposed in two places: in our @hl.scala{upickle.Js.*} AST:

    @hl.scala
      /**
      * A very small, very simple JSON AST that uPickle uses as part of its
      * serialization process. A common standard between the Jawn AST (which
      * we don't use so we don't pull in the bulk of Spire) and the Javascript
      * JSON AST.
      */
      object Js {

        sealed trait Value extends Any {
          def value: Any

          /**
            * Returns the `String` value of this [[Js.Value]], fails if it is not
            * a [[Js.Str]]
            */
          def str = this match{
            case Str(value) => value
            case _ => throw Invalid.Data(this, "Expected Js.Str")
          }
          /**
            * Returns the key/value map of this [[Js.Value]], fails if it is not
            * a [[Js.Obj]]
            */
          def obj = this match{
            case Obj(value @@_*) => value.toMap
            case _ => throw Invalid.Data(this, "Expected Js.Obj")
          }
          /**
            * Returns the elements of this [[Js.Value]], fails if it is not
            * a [[Js.Arr]]
            */
          def arr = this match{
            case Arr(value @@ _*) => value
            case _ => throw Invalid.Data(this, "Expected Js.Arr")
          }
          /**
            * Returns the `Double` value of this [[Js.Value]], fails if it is not
            * a [[Js.Num]]
            */
          def num = this match{
            case Num(value) => value
            case _ => throw Invalid.Data(this, "Expected Js.Num")
          }

          /**
            * Looks up the [[Js.Value]] as a [[Js.Arr]] using an index, throws
            * otherwise if it's not a [[Js.Arr]]
            */
          def apply(i: Int): Value = this.arr(i)
          /**
            * Looks up the [[Js.Value]] as a [[Js.Obj]] using an index, throws
            * otherwise if it's not a [[Js.Obj]]
            */
          def apply(s: java.lang.String): Value = this.obj(s)

          override def toString = upickle.json.write(this, indent = 4)
        }
        case class Str(value0: java.lang.CharSequence) extends Value{
          lazy val value: String = value0.toString
        }
        case class Obj(value0: (java.lang.CharSequence, Value)*) extends Value{
          lazy val value: Seq[(String, Value)] = value0.map{case (k, v) => (k.toString, v)}
        }
        case class Arr(value: Value*) extends AnyVal with Value
        case class Num(value: Double) extends AnyVal with Value
        case object False extends Value{
          def value = false
        }
        case object True extends Value{
          def value = true
        }
        case object Null extends Value{
          def value = null
        }
      }

    @p
      As well as in the @hl.scala{upickle.json.read} and @hl.scala{upickle.json.write} functions:

    @hl.scala
      def read(s: String): Js.Value
      def write(v: Js.Value): String

    @p
      Which you use to convert between structured @hl.scala{Js.*} trees and unstructured @hl.scala{String}s. As described earlier, the implementation of these functions differs between ScalaJVM/ScalaJS.
    @p
      You can use this JSON data structure for simple tasks:

    @hl.ref(wd/'upickle/'shared/'src/'test/'scala/'upickle/"JsonTests.scala", Seq("'shortcuts", "'positive", ""))
    @hl.ref(wd/'upickle/'shared/'src/'test/'scala/'upickle/"JsonTests.scala", Seq("'correctness", ""))

    @p
      uPickle does not provide any other utilities are JSON that other libraries do (zippers, lenses, combinators, ...). If you're looking for a compact JSON AST to construct or pattern match on, together with fast serializing and deserializing, it may do the trick.

    @p
      uPickle's @hl.scala{Js.Value} type and subclasses are all themselves
      serializable, and they serialize to themselves.


  @sect{Why uPickle}
    @p

      I wrote uPickle because I needed a transparent serialization library that worked both in Scala-JVM and Scala-JS, and my dissatisfaction with existing solutions:
    @ul
      @li
        None of the libraries I could find were pure Scala: @a("spray-json", href:="https://github.com/spray/spray-json") uses @a("parboiled1", href:="https://github.com/sirthias/parboiled/wiki") which is written in Java, @a("play-json", href:="http://www.playframework.com/documentation/2.2.x/ScalaJson") uses @a("Jackson", href:="http://jackson.codehaus.org/"), which uses Java/reflection. @a("scala-pickling", href:="https://github.com/scala/pickling") silently falls back to reflection. This makes them difficult to port to ScalaJS, which supports neither Java nor reflection.
      @li
        Those libraries also typically have non-trivial dependency chains. That also makes them hard to port to ScalaJS, since I'd need to port all of their dependencies too.
      @li
        Lastly, many aim for a very ambitious target: untyped serialization of arbitrary object graphs. That forces them to use reflection, and makes their internals and semantics much more complex.
    @p
      uPickle on the other hand aims much lower: by limiting the scope of the problem to statically-typed, tree-like, immutable data structures, it greatly simplifies both the internal implementation and the external API and behavior of the library. uPickle serializes objects using a very simple set of rules ("Does it have an implicit? Is it a class with @hl.scala{apply}/@hl.scala{unapply} on the companion?") that makes its behavior predictable and simple to understand.

  @sect{Version History}
    @sect{0.5.1}
      @ul
        @li
          Strip out automatic "deep" case-class serialization: you must now
          define a serializer for each case class you want to deal with, preferably
          in the companion object
        @li
          Upgrade Jawn version to 0.11.0, add helpers in @code{upickle.json} to
          parse JSON coming from files.
        @li
          New @code{upickle.json.writeTo} function for serializing JSON directly
          to a @code{java.io.Writer}, rather than creating a @code{String}

        @li
          @code{upickle.json.write} now takes an optional `sortKeys` flag, if
          you want the JSON dictionaries to rendered in a standardized order

        @li
          Drop support fo Scala 2.10
    @sect{0.4.3}
      @ul
        @li
          Support for @hl.scala{BigInt} and @hl.scala{BigDecimal},
          thanks to @lnk("Jisoo Park", "https://github.com/guersam")
        @li
          @code{Js.Value}s are now serializable, thanks to
          @lnk("Felix Dietze", "https://github.com/fdietze")
        @li
          Made it easy to write @sect.ref{Manual Sealed Trait Picklers}
          in order to work around problems with SI-7046
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.2")
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.1")
    @sect{0.4.0}
      @ul
        @li
          Allow custom handling for JSON @hl.scala{null}s via a @sect.ref{Custom Configuration}
        @li
          Made @hl.scala{upickle.key} a @hl.scala{case class}
        @li
          Remove unnecessary dependency of @hl.scala{derive} on default arguments #143
        @li
          Fixed derivation allowing Caching Picklers in a @hl.scala{case class}'s companion object, potentially speeding up compilation times and runtimes
    @sect{0.3.9}
      @ul
        @li
          Add @hl.scala{.arr: Seq[Js.Value]}, @hl.scala{.obj: Map[String, Js.Value]}, @hl.scala{.str: String} and @hl.scala{.num: Double} helper methods on @hl.scala{Js.Value} to simplify usage as a simple JSON tree.
        @li
          @hl.scala{Invalid.Json} and @hl.scala{Invalid.Data} now have better exception messages by default, which should simplify debugging
        @li
          Some usages should compile faster due to fiddling with implicits (#138)
    @sect{0.3.8}
      @ul
        @li
          Tweaks to PPrint
    @sect{0.3.7}
      @ul
        @li
          You can now pass in an @hl.scala{indent} parameter to @hl.scala{upickle.default.write} in order to format/indent the JSON nicely across multiple lines
        @li
          Derivation based on sealed abstract classes works, in addition to traits (#104), thanks to @a("Voltir", href:="https://github.com/Voltir")
        @li
          Fix non-deterministic failure due to improperly implemented @code{equals}/@code{hashCode} in macro (#124), thanks to @a("Voltir", href:="https://github.com/lihaoyi/upickle-pprint/issues/124")
        @li
          Slightly improve hygiene of uPickle/PPrint macro expansion
        @li
          uPickle de-serialization failures should no longer throw @code{MatchErrors} (#101)
        @li
          Using case-class-derived @code{Reader}s/@code{Writer}s should no longer fail in class @code{extends} clauses (#108)
        @li
          @code{Float.NaN} and @code{Double.NaN} are now properly handled (#123)
        @li
          Provided an example of a @sect.ref{Custom Configuration} being used to @code{snake_case} case-class fields during serialization/de-serialization (#120)

    @sect{0.3.6}
      @ul
        @li
          Fix more bugs in PPrint derivation
    @sect{0.3.5}
      @ul
        @li
          Fix some bugs in PPrint derivation
    @sect{0.3.4}
      @ul
        @li
          Remove unnecessary shapeless dependency
    @sect{0.3.3}
      @ul
        @li
          Fix more edge cases to avoid diverging implicits
    @sect{0.3.2}
      @ul
        @li
          Fix more edge cases around typeclass derivation: #94, #95, #96
        @li
          Don't get tripped up by custom Apply methods: #48
    @sect{0.3.1}
      @ul
        @li
          Fixed edge cases around typeclass derivation

    @sect{0.3.0}
      @ul
        @li
          Top-to-bottom rewrite of type-class derivation macros. Much faster, more reliable, etc.. Still one or two cases where it misbehaves, but much fewer than before. Extracted it into the @hl.scala{derive} subproject
        @li
          Force users to choose between @hl.scala{import upickle.default._} which now renders sealed trait hierarchies as dictionaries with a @hl.scala{$type} attribute, and @hl.scala{import upickle.legacy._} which does the old-style array-wrapper.
        @li
          You can also now create your own custom subclass of @hl.scala{upickle.Api} if you wish to customize things further, e.g. changing the type-attribute or changing the rendering of case classes.

    @sect{0.2.8}
      @ul
        @li
          Support for @hl.scala{java.util.UUID}, which are serialized as strings in the standard format

    @sect{0.2.7}
      @ul
        @li
          Re-published for Scala.js 0.6.1

    @sect{0.2.6}
      @ul
        @li
          @hl.scala{'Symbol}s are now read/write-able by default
        @li
          Added lots of warnings for common issues
        @li
          @hl.scala{Map[String, V]} now pickles to a JSON dictionary @hl.scala(""""key": "value", ...}"""). @hl.scala{Map[K, V]} for all other @hl.scala{K != String} are unchanged
        @li
          Source maps now point towards a reasonabel place on Github


    @sect{0.2.5}
      @ul
        @li
          Fixed [#23](https://github.com/lihaoyi/upickle/issues/23): self-recursive data structures are now supported.
        @li
          Fixed [#18](https://github.com/lihaoyi/upickle/issues/18): you can now auto-pickle classes in objects that originated from traits that were mixed in.


    @sect{0.2.4}
      @ul
        @li
          Support reading and writing @hl.scala{null}
        @li
          Fixed Reader/Writer macros for single-class sealed hierarchies
        @li
          Used @hl.scala{CanBuildFrom} to serialize a broader range of collections

    @sect{0.2.3}
      @ul
        @li
          Added a pickler for @hl.scala{Unit}/@hl.scala{()}

    @sect{0.2.2}
      @ul
        @li
          Swapped over from the hand-rolled parser to using @hl.scala{Jawn}/@hl.scala{JSON.parse} on the two platforms, resulting in a 10-15x speedup for JSON handling.
        @li
          Renamed @hl.scala("""Js.{String, Object, Array, Number}""") into @hl.scala("""Js.{Str, Obj, Arr, Num}"""), and made @hl.scala{Js.Arr} and @hl.scala{Js.Obj} use varargs, to allow for better direct-use.
        @li
          Documented and exposed JSON API for direct use by users of the library.

    @sect{0.2.1}
      @ul
        @li
          Improved error messages for unpickle-able types
        @li
          ScalaJS version now built against 0.5.3

    @sect{0.2.0}
      @ul
        @li
          Members of sealed trait/class hierarchies are now keyed with the fully-qualified name of their class, rather than an index, as it is less likely to change due to adding or removing classes
        @li
          Members of sealed hierarchies and parameters now support a @hl.scala{upickle.key("...")} annotation, which allows you to override the default key used (which is the class/parameter name) with a custom one, allowing you to change the class/param name in your code while maintaining compatibility with serialized structures
        @li
          Default parameters are now supported: they are used to substitute missing keys when reading, and cause the key/value pair to be omitted if the serialized value matches the default when writing
        @li
          Missing keys when deserializing case classes now throws a proper @hl.scala{Invalid.Data} exception
        @li
          @hl.scala{object}s are now serialized as @hl.scala("""{}""") rather than @hl.scala{[]}, better matching the style of case classes
        @li
          0-argument case classes, previously unsupported, now serialize to @hl.scala("""{}""") the same way as @hl.scala{object}s
        @li
          Fixed a bug that was preventing multi-level sealed class hierarchies from being serialized due to a compilation error
        @li
         Fixed a bug causing case classes nested in other packages/objects and referred to by their qualified paths to fail pickling
        @li
          Tightened up error handling semantics, swapping out several @hl.scala{MatchError}s with @hl.scala{Invalid.Data} errors

    @sect{0.1.7}
      @ul
        @li
          Cleaned up the external API, marking lots of things which should have been private private or stuffing them in the @hl.scala{Internals} namespace
        @li
          Organized things such that only a single import @hl.scala{import upickle._} is necessary to use the library

    @sect{0.1.6}
      @ul
        @li
          Tuples and case classes now have implicit picklers up to an arity limit of 22.
        @li
          Case classes now serialize as JSON dictionaries rather than as lists.

    @sect{0.1.5}
      @ul
        @li
          Simple case classes and case class hierarchies are now auto-serializable view Macros. No need to define your own implicit using @hl.scala{Case0ReadWriter} anymore!

    @sect{0.1.4}
      @ul
        @li
          Serialize numbers as JSON numbers instead of Strings.

    @sect{0.1.3}
      @ul
        @li

          Specification of the exception-throwing behavior: instead of failing with random @hl.scala{MatchError}s or similar, parse failures now are restricted to subclasses @hl.scala{upickle.Invalid} which define different failure modes.
