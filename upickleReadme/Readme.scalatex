
@import Main._


@def lnk(txt: String, url: String) = a(txt, href:=url)
@val exampleTests = wd/'upickle/'test/"src"/'upickle/'example/"ExampleTests.scala"
@val derivationTests = wd/'upickle/'test/"src-3"/'upickle/"DerivationTests.scala"
@val enumTests = wd/'upickle/'test/"src-3"/'upickle/"EnumTests.scala"
@val jvmExampleTests = wd/'upickle/'test/"src-jvm-2"/'upickle/'example/"JvmExampleTests.scala"
@val macroTests = wd/'upickle/'test/'src/'upickle/"MacroTests.scala"

@val optionsAsNullTests =  wd/'upickle/'test/"src"/'upickle/'example/"OptionsAsNullTests.scala"


@a(
  href := "https://github.com/lihaoyi/upickle-pprint",
  img(
    position.absolute,
    top := 0,
    right := 0,
    border := 0,
    src := "https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67",
    alt := "Fork me on GitHub",
    data.`canonical-src` := "https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
  )
)

@sect("uPickle 3.0.0")
  @div(display.flex, alignItems.center, flexDirection.column)
    @div
      @a(href := "https://gitter.im/lihaoyi/upickle")(
        img(src := "https://badges.gitter.im/Join%20Chat.svg")
      )
      @span(" ")
      @a(href := "https://www.patreon.com/lihaoyi")(
        img(src := "https://img.shields.io/badge/patreon-sponsor-ff69b4.svg")
      )

  @p
    uPickle (pronounced micro-pickle) is a lightweight JSON and binary (MessagePack)
    serialization library for Scala. It's key features are:
  @ul
    @li
      @sect.ref("Getting Started", "Simple to use"), with nice human-readable JSON output
    @li
      Very high @sect.ref{Performance}; faster than
      @lnk("Play-Json", "https://github.com/playframework/play-json"),
      @lnk("Circe", "https://github.com/circe/circe"), or
      @lnk("Argonaut", "https://github.com/argonaut-io/argonaut")
      by a large margin
    @li
      Simple & easy to understand @sect.ref("uJson", "JSON Processing API"),
      that should be instantly familiar to anyone whose processed JSON in
      Python, Ruby, or Javascript
    @li
      Flexible and easily @sect.ref("Customization", "customizable")
    @li
      Zero dependencies; can be included in any project without worrying about
      conflicts
    @li
      @sect.ref("ScalaJS") support, allowing transfer of structured data
      between the JVM and Javascript
    @li
      Supports binary serialization via the MessagePack format, for even faster
      serialization/de-serialization and smaller payloads.

  @p
    This documentation is meant as a thorough reference to this library. For a hands-on
    introduction, take a look at the following blog post:

  @ul
    @li
      @lnk("How to work with JSON in Scala", "http://www.lihaoyi.com/post/HowtoworkwithJSONinScala.html")

  @sect{Getting Started}
    @hl.scala
      "com.lihaoyi" %% "upickle" % "3.0.0" // SBT
      ivy"com.lihaoyi::upickle:3.0.0" // Mill

    @p
      And then you can immediately start writing and reading common Scala
      objects to strings:

    @hl.ref(exampleTests, Seq("\"simple\"", ""))

    @p
      Or to compact byte arrays, using the @lnk("MessagePack", "https://msgpack.org/index.html")
      format:

    @hl.ref(exampleTests, Seq("\"binary\"", ""))

    @sect{ScalaJS}
      @p
        For ScalaJS applications, use this dependencies instead:
      @hl.scala
        "com.lihaoyi" %%% "upickle" % "3.0.0" // SBT
        ivy"com.lihaoyi::upickle::3.0.0" // Mill

    @sect{Scala Versions}
      @p

        uPickle supports Scala 2.12, 2.13 and 3.1+

  @sect{Basics}
    @sect{Builtins}
      @p
        This is a non-comprehensive list of what the most commonly-used types
         pickle to using uPickle. To begin, let's import upickle

      @hl.scala
        import upickle.default._

      @sect{Primitives}
        @p
          Booleans are serialized as JSON booleans

        @hl.ref(exampleTests, Seq("\"more\"", "\"booleans\"", ""))

        @p
          Numbers are serialized as JSON numbers

        @hl.ref(exampleTests, Seq("\"more\"", "\"numbers\"", ""))

        @p
          Except for @hl.scala{Long}s, which too large for Javascript. These are
          serialized as JSON Strings, keeping the interchange format compatible
           with the browser's own JSON parser, which provides the best
            performance in Scala.js

        @hl.ref(exampleTests, Seq("\"more\"", "\"longs\"", ""))

        @p
          Special values of @hl.scala{Double}s and @hl.scala{Float}s are also
          serialized as Strings

        @hl.ref(exampleTests, Seq("\"more\"", "\"specialNumbers\"", ""))



        @p
          Both @hl.scala{Char}s and @hl.scala{String}s are serialized as Strings

        @hl.ref(exampleTests, Seq("\"more\"", "\"charStrings\"", ""))
      @sect{Collections}
        @p
          @code{Array}s and most immutable collections are serialized as JSON lists

        @hl.ref(exampleTests, Seq("\"more\"", "\"seqs\"", ""))

        @p
          @code{Option}s are serialized as JSON lists with 0 or 1 element

        @hl.ref(exampleTests, Seq("\"more\"", "\"options\"", ""))


        @p
          Tuples of all sizes (1-22) are serialized as heterogenous JSON lists

        @hl.ref(exampleTests, Seq("\"more\"", "\"tuples\"", ""))

        @p
          @code{Map}s with primitive keys are serialized into JSON dictionaries,
          while @code{Map} with complex keys are serialized into lists of
          2-element tuples

        @hl.ref(exampleTests, Seq("\"more\"", "\"maps\"", ""))

      @sect{Case Classes}
        @p
          Case classes of sizes 1-64 are serialized as JSON dictionaries with the
          keys being the names of each field.
          To begin with, you need to define a serializer in the Case Class's
          companion object:

        @hl.scala
          import upickle.default.{ReadWriter => RW, macroRW}

        @p
          After that, you can begin serializing that case class.

        @hl.ref(exampleTests, Seq("object Simple", ""))
        @hl.ref(exampleTests, Seq("\"more\"", "\"caseClass\"", ""), "        }")

        @p
          Sealed hierarchies are serialized as tagged values, the serialized
          object tagged with the full name of the instance's class:

        @hl.ref(exampleTests, Seq("object Sealed", ""))
        @hl.ref(exampleTests, Seq("\"more\"", "\"sealed\"", ""), "  }")

        @p
          Serializability is recursive; you can serialize a type only if all
          its members are serializable. That means that collections, tuples and
          case-classes made only of serializable members are themselves serializable

        @hl.ref(exampleTests, Seq("object Recursive", ""))
        @hl.ref(exampleTests, Seq("\"more\"", "\"recursive\"", ""), "  }")
      @sect{Scala 3 Deriving}
        @p
          In Scala 3, you can use the @hl.scala{derives} keyword on standalone
          @hl.scala{case class}es, @hl.scala{sealed trait} hierarchies, and
          @hl.scala{enum}s:

        @hl.ref(derivationTests, "case class Dog", "")
        @hl.ref(derivationTests, Seq("\"example\"", "\"dog\"", ""))

        @hl.ref(derivationTests, Seq("sealed trait Animal"), Seq("case object Cthulu", ""))
        @hl.ref(derivationTests, Seq("\"example\"", "\"animal\"", ""))

        @hl.ref(enumTests, "enum SimpleEnum", "end SimpleEnum")
        @hl.ref(enumTests, Seq("example", "simple", ""))

        @hl.ref(enumTests, "enum ColorEnum", "end ColorEnum")
        @hl.ref(enumTests, Seq("example", "color", "Enclosing"))
      @p
        Note that you only need to put the @hl.scala{derives} keyword on the
        @hl.scala{enum}s or @hl.scala{sealed trait}s, and not on all the
        individual @hl.scala{case class}es or @hl.scala{case object}s.

      @p
        Also, note that for @hl.scala{enum}s, the short un-qualified name is used
        for the type key, rather than the fully qualified name with package path.
        This is because unlike @hl.scala{sealed trait}s, @hl.scala{enum}s enforce
        that every case is in the same flat namespace, and thus the short name is
        enough to dis-ambiguate them. This behavior can be overriden with the
        @hl.scala("""@key("...")""") annotation in both cases, if a different type key
        is desired.

    @sect{Read/Writing Other Things}

      @p
        Apart from reading & writing @code{java.lang.String}s, allows you to easily
        read from alternate sources such as @code{CharSequence}s, @code{Array[Byte]}s,
        @code{java.io.File}s and @code{java.nio.file.Path}s:

      @hl.ref(exampleTests, Seq("\"sources\"", ""), "  }")
      @hl.ref(jvmExampleTests, Seq("\"sources\"", ""), "  }")

      @p
        Reading from large files is automatically streamed so you do not read the
        entire file into memory. You can use @code{writeTo} to serialize your
        data to an arbitrary @code{java.io.Writer}/@code{java.io.OutputStream}:
        this can be streamed directly to files or over the network without having
        to accumulate the serialized JSON in memory.
    @sect{Nulls}
      @p
      
        Nulls serialize into JSON nulls, as you would expect
      
      @hl.ref(exampleTests, Seq("\"more\"", "\"null\"", ""), "  }")
      
      @p
        uPickle only throws exceptions on unpickling; if a pickler is
        properly defined, serializing a data structure to a @hl.scala{String}
        should never throw an exception.
      
      @p
        All these examples can be similarly serialized to MessagePack-formatted
        binaries, in the same way: JSON booleans become MessagePack booleans,
        lists become MessagePack lists, and so on. Reading and writing
        MessagePack binary data is typically significantly faster than reading
        and writing JSON, and the serialized data is also significantly smaller.

    @sect{Defaults}

      @p
        If a field is missing upon deserialization, uPickle uses the default
        value if one exists

      @hl.ref(exampleTests, Seq("\"defaults\"", "\"reading\"", ""), "  }")

      @p

        If a field at serialization time has the same value as the default,
         uPickle leaves it out of the serialized blob

      @hl.ref(exampleTests, Seq("\"defaults\"", "\"writing\"", ""), "  }")

      @p

        This allows you to make schema changes gradually, assuming you have
        already pickled some data and want to add new fields to the case classes
        you pickled. Simply give the new fields a default value (e.g.
        @hl.scala{""} for Strings, or wrap it in an @hl.scala{Option[T]} and
        make the default @hl.scala{None}) and uPickle will happily read the
        old data, filling in the missing field using the default value.

    @sect{Supported Types}
      @p
        Out of the box, uPickle supports writing and reading the following types:
      @ul
        @li
          @hl.scala{Boolean}, @code{Byte}, @code{Char}, @code{Short},
          @code{Int}, @code{Long}, @code{Float}, @code{Double}
        @li
          @code{Tuple}s from 1 to 22
        @li
          Immutable @code{Seq}, @code{List}, @code{Vector}, @code{Set},
          @code{SortedSet}, @code{Option}, @code{Array}, @code{Map}s, and all
          other collections with a reasonable @hl.scala{CanBuildFrom} implementation
        @li
          @code{Duration}, @code{Either}
        @li
          Stand-alone @hl.scala{case class}es and @hl.scala{case object}s, and
           their generic equivalents,
        @li
          Non-generic @hl.scala{case class}es and @hl.scala{case object}s that
          are part of a @hl.scala{sealed trait} or @hl.scala{sealed class} hierarchy
        @li
          @hl.scala{sealed trait} and @hl.scala{sealed class}es themselves,
           assuming that all subclasses are picklable
        @li
          @code{UUID}s
        @li
          @hl.scala{null}
      @p
        Readability/writability is recursive: a container such as a @code{Tuple}
        or @hl.scala{case class} is only readable if all its contents are
         readable, and only writable if all its contents are writable. That means
          that you cannot serialize a @hl.scala{List[Any]}, since uPickle doesn't
           provide a generic way of serializing @code{Any}. Case classes are only
           serializable up to 64 fields.

      @p
        Case classes are serialized using the @hl.scala{apply} and
        @hl.scala{unapply} methods on their companion objects. This means that
        you can make your own classes serializable by giving them companions
         @hl.scala{apply} and @hl.scala{unapply}. @hl.scala{sealed} hierarchies
         are serialized as tagged unions: whatever the serialization of the
         actual object, together with the fully-qualified name of its class, so
          the correct class in the sealed hierarchy can be reconstituted later.

      @p
        That concludes the list of supported types. Anything else is not supported
        by default, but you can add support using @sect.ref{Custom Picklers}

    @sect{Common Operations}
      @p
        The following common operations are available on any uPickle module,
        e.g. @code{upickle.default} or @code{upickle.legacy}:

      @hl.ref(wd/'upickle/'src/'upickle/"Api.scala", Seq("trait Api"), "// End Api")

  @sect{Customization}
    @sect{Custom Picklers}
      @hl.ref(exampleTests, Seq("\"mapped\"", "\"simple\"", ""), "}")

      @p
        You can use the @code{readwriter[T].bimap[V]} function to create a pickler
        that reads/writes a type @code{V}, using the pickler for type @code{T},
        by providing a conversion function between them.

      @p
        The type you are @code{.bimap}ing to doesn't need to be a case class,
        or be pickleable in any way, as long as the type you are
        @code{.bimap}ing from is pickleable. The following example demonstrates
        using @code{.bimap} to define a serializer for non-case Scala class

      @hl.ref(exampleTests, Seq("object Custom2", ""))

      @p
        Note that when writing custom picklers, it is entirely up to you to get
        it right, e.g. making sure that an object that gets round-trip
        pickled/unpickled comes out the same as when it started.

      @p
        Lastly, if you want more control over exactly how something is serialized,
        you can use @code{readwriter[Js.Value].bimap} to give yourself access to
        the raw JSON AST:

      @hl.ref(exampleTests, Seq("\"mapped\"", "\"Value\"", ""))

    @sect{Custom Keys}
      @p

        uPickle allows you to specify the key that a field is serialized with
        via a @hl.scala{@@key} annotation


      @hl.ref(exampleTests, Seq("object Keyed", ""))
      @hl.ref(exampleTests, Seq("\"keyed\"", "\"attrs\"", ""))

      @p

        Practically, this is useful if you want to rename the field within your
        Scala code while still maintaining backwards compatibility with
        previously-pickled objects. Simple rename the field and add a
        @hl.scala{@@key("...")} with the old name so uPickle can continue to work
        with the old objects correctly.
      @p
        You can also use @hl.scala{@@key} to change the name used when pickling
        the case class itself. Normally case classes are pickled without their
        name, but an exception is made for members of sealed hierarchies which
        are tagged with their fully-qualified name. uPickle allows you to use
        @hl.scala{@@key} to override what the class is tagged with:

      @hl.ref(exampleTests, Seq("object KeyedTag", ""))
      @hl.ref(exampleTests, Seq("\"keyed\"", "\"tag\"", ""))



      @p
        This is useful in cases where:
      @ul
        @li
          you wish to rename the class within your Scala code, or move it to a
          different package, but want to preserve backwards compatibility with
          previously pickled instances of that class
        @li
          you try to tackle the resource issue (bandwidth, storage, CPU) because
          FQNs might get quite long

    @sect{JSON Dictionary Formats}
      @p
        By default, serializing a @hl.scala{Map[K, V]} generates a nested
        array-of-arrays. This is because not all types @code{K} can be
        easily serialized into JSON strings, so keeping them as nested tuples
        preserves the structure of the serialized @code{K} values:

      @hl.ref(exampleTests, Seq("nonCustomMapKeys", ""))

      @p
        For types of @code{K} that you want to serialize to JSON strings in
        JSON dictionaries, you can wrap your @hl.scala{ReadWriter[K]} in a
        @hl.scala{stringKeyRW}.

      @hl.ref(exampleTests, Seq("customMapKeys", ""))

      @p
        Note that this only works for types @code{K} which serialize to JSON
        primitives: numbers, strings, booleans, and so on. Types of @code{K}
        that serialize to complex structures like JSON arrays or dictionaries
        are unsupported for use a JSON dictionary keys.

      @p
        Older versions of uPickle serialized almost all @hl.scala{Map[K, V]}s to
        nested arrays. Data already serialized in that format is forwards-compatible
        with the current implementation of uPickle, which can read both nested-json-arrays
        and json-dictionary formats without issue.

      @p
        These subtleties around deciding between nested-json-array v.s. json-dictionary
        formats only apply to uPickle's JSON backend. When serializing to MessagePack
        using @hl.scala{upickle.default.writeBinary} or @hl.scala{upickle.default.writeMsg},
        it always uses the dictionary-based format, since MessagePack does not have
        the restriction that dictionary keys can only be strings:

      @hl.ref(exampleTests, Seq("msgPackMapKeys", ""))

    @sect{Custom Configuration}
      @p
        Often, there will be times that you want to customize something on a
        project-wide level. uPickle provides hooks in letting you subclass the
        @hl.scala{upickle.Api} trait to create your own bundles apart from the
        in-built @hl.scala{upickle.default} and @hl.scala{upickle.legacy}. The
        following example demonstrates how to customize a bundle to
        automatically @code{snake_case} all dictionary keys.

        @hl.ref(exampleTests, Seq("\"snakeCase\"", ""))

      @p
        If you are using uPickle to convert JSON from another source into Scala
        data structures, you can also configure it to map @hl.scala{Option[T]}s
        to @code{null}s when the option is @code{None}:

      @hl.ref(optionsAsNullTests, "object OptionPickler", "// end_ex")

      @p
        This custom configuration allows you to treat @hl.scala{null}s as
        @hl.scala{None}s and anything else as @hl.scala{Some(...)}s. Simply
        @hl.scala{import OptionPickler._} instead of the normal uPickle import
        throughout your project and you'll have the customized reading/writing
        available to you.

      @p
        You can also use a custom configuration to change how 64-bit @code{Long}s are
        handled. By default, small longs that can be represented exactly in 64-bit
        @code{Double}s are written as raw numbers, while larger values (n > 2^53)
        are written as strings. This is to ensure the values are not truncated when
        the serialized JSON is then manipulated, e.g. by Javascript which truncates
        all large numbers to Doubles. If you wish to always write Longs as Strings,
        or always write them as numbers (at risk of truncation), you can do so as
        follows:

      @hl.ref(exampleTests, Seq("stringLongs", ""))


  @sect{Limitations}

    @p
      uPickle doesn't currently support:
    @ul
      @li
        Circular object graphs
      @li
        Reflective reading and writing
      @li
        Read/writing of untyped values e.g. @code{Any}
      @li
        Read/writing arbitrarily shaped objects
      @li
        Read/writing case classes with multiple parameter lists.
    @p
      Most of these limitations are inherent in the fact that ScalaJS does not
      support reflection, and are unlikely to ever go away. In general, uPickle
      by default can serialize statically-typed, tree-shaped, immutable data
      structures. Anything more complex requires @sect.ref{Custom Picklers}

    @sect{Manual Sealed Trait Picklers}
      @p
        Due to a bug in the Scala compiler SI-7046, automatic sealed trait
        pickling can fail unpredictably. This can be worked around by instead
        using the @code{macroRW} and @code{merge} methods to manually specify
        which sub-types of a sealed trait to consider when pickling:

      @hl.ref(macroTests, "sealed trait TypedFoo", "// End TypedFoo")

  @sect{uJson}

    @p
      uJson is uPickle's JSON library, which can be used to easily
      manipulate JSON source and data structures without converting them into
      Scala case-classes. This all lives in the @code{ujson} package. Unlike
      many other Scala JSON libraries that come with their own zoo of new
      concepts, abstractions, and techniques, uJson has a simple & predictable
      JSON API that should be instantly familiar to anyone coming from
      scripting languages like Ruby, Python or Javascript.

    @p
      uJson comes bundled with uPickle, or can be used stand-alone via the
      following package coordinates:

    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "ujson" % "0.9.6"

    @sect{Construction}
      @p
        You can use @code{ujson} to conveniently construct JSON blobs, either
        programmatically:
      @hl.ref(exampleTests, Seq("\"json\"", "\"construction\"", ""), "}")

      @p
        Or parsing them from strings, byte arrays or files:

      @hl.ref(exampleTests, Seq("\"json\"", "\"simple\"", ""), "}")

      @p
        @code{ujson.Js} ASTs are mutable, and can be modified before being re-serialized
        to strings:

      @hl.ref(exampleTests, Seq("\"json\"", "\"mutable\"", ""), "}")

      @p
        You can also use the `_` shorthand syntax to update a JSON value in
        place, without having to duplicate the whole path:

      @hl.ref(exampleTests, Seq("\"json\"", "\"update\"", ""), "}")

      @p
        case classes or other Scala data structures can be converted to
        @code{ujson.Js} ASTs using @code{upickle.default.writeJs}, and the
        @code{ujson.Js} ASTs can be converted back using @code{upickle.default.readJs}
        or plain @code{upickle.default.read}:

      @hl.ref(exampleTests, Seq("\"json\"", "\"intermediate\"", ""), "}")

    @sect{JSON Utilities}
      @p
        uJson comes with some convenient utilities on the `ujson` package:

      @hl.ref(wd/'ujson/'src/'ujson/"package.scala", Seq("package object ujson", ""), "// End ujson")

    @sect{Transformations}
      @p
        uJson allows you seamlessly convert between any of the following forms
        you may find your JSON in:

      @ul
        @li
          Case classes & Scala data-types
        @li
          @code{ujson.Js} ASTs
        @li
          @code{String}s
        @li
          @code{CharSequence}s
        @li
          @code{Array[Byte]}s
        @li
          Third-party JSON ASTs (Argonaut, Circe, Json4s, Play-Json)
      @p
        This is done using the @code{ujson.transform(source, dest)} function:

      @hl.ref(exampleTests, Seq("\"json\"", "\"misc\"", ""), "}")

      @p
        All transformations from A to B using @code{ujson.transform} happen
        in a direct fashion: there are no intermediate JSON ASTs being generated,
        and performance is generally very good.

      @p
        You can use @code{ujson.transform} to validate JSON in a streaming
        fashion:

      @hl.ref(exampleTests, Seq("\"json\"", "\"validate\"", ""), "}")

      @p
        The normal @code{upickle.default.read/write} methods to serialize Scala
        data-types is just shorthand for ujson.transform,
        using a @code{upickle.default.transform(foo)} as the source or a
        @code{upickle.default.reader[Foo]} as the destination:

      @hl.ref(exampleTests, Seq("\"json\"", "\"upickleDefault\"", ""), "}")

    @sect{Other ASTs}
      @p
        uJson does not provide any other utilities are JSON that other libraries
        do: zippers, lenses, combinators, etc.. However, uJson can be used to
        seamlessly convert between the JSON AST of other libraries! This means
        if some other library provides a more convenient API for some kind of
        processing you need to do, you can easily parse to that library's AST,
        do whatever you need, and convert back after.

      @p
        As mentioned earlier, conversions are fast and direct, and happen
        without creating intermediate JSON structures in the process. The
        following examples demonstrate how to use the conversion modules for
        @lnk("Argonaut", "http://argonaut.io/doc/"),
        @lnk("Circe", "https://github.com/circe/circe"),
        @lnk("Json4s", "https://github.com/json4s/json4s"), and
        @lnk("Play Json", "https://github.com/playframework/play-json").
      @p
        Each example parses JSON from a string into that particular library's
        JSON AST, manipulates the AST using that library, un-pickles it into
        Scala data types, then serializes those data types first into that
        library's AST then back to a st.ring

      @sect{Argonaut}
        @b{Maven Coordinates}

        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-argonaut" % "0.9.6"

        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("\"argonaut\"", ""), "}")

      @sect{Circe}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-circe" % "0.9.6"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("\"circe\"", ""), "}")

      @sect{Play-Json}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-play" % "0.9.6"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("\"playJson\"", ""), "}")

      @sect{Json4s}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-json4s" % "0.9.6"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("\"json4s\"", ""), "}")

      @sect{Cross-Library Conversions}
        @p
          uJson lets you convert between third-party ASTs efficiently and with
          minimal overhead: uJson converts one AST to the other directly
          and without any temporary compatibility data structures. The following
          example demonstrates how this is done: we parse a JSON string using
          Circe, perform some transformation, convert it to a Play-Json AST,
          perform more transformations, and finally serialize it back to a
          String and check that both transformations were applied:

        @hl.ref(jvmExampleTests, Seq("\"crossAst\"", ""), "}")

  @sect{uPack}

    @p
      uPack is uPickle's MessagePack library, which can be used to easily
      manipulate MessagePack source and data structures without converting them into
      Scala case-classes. This all lives in the @code{upack} package.
    @p
      uPack comes bundled with uPickle, or can be used stand-alone via the
      following package coordinates:

    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "upack" % "0.9.6"

    @p
      The following basic functions are provided in the @code{upack} package
      to let you read and write MessagePack structs:

    @hl.ref(wd/'upack/'src/'upack/"package.scala", Seq("package object upack", ""))

    @p
      MessagePack structs are represented using the @code{upack.Msg} type.
      You can construct ad-hoc MessagePack structs using @code{upack.Msg}, and
      can similarly parse binary data into @code{upack.Msg} for ad-hoc querying
      and manipulation, without needing to bind it to Scala case classes or data
      types:

    @hl.ref(wd/'upickle/'test/'src/'upickle/'example/"ExampleTests.scala", Seq("\"msgConstruction\"", ""))

    @p
      You can read/write Scala values to @code{upack.Msg}s using @code{readBinary}/@code{writeMsg}:

    @hl.ref(wd/'upickle/'test/'src/'upickle/'example/"ExampleTests.scala", Seq("\"msgReadWrite\"", ""))

    @p
      Or include @code{upack.Msg}s inside @code{Seq}s, case-classes and other
      data structures when you read/write them:

    @hl.ref(wd/'upickle/'test/'src/'upickle/'example/"ExampleTests.scala", Seq("\"msgInsideValue\"", ""))

    @p
      You can also convert the uPack messages or binaries to @code{ujson.Value}s via
      @code{upack.transform}. This can be handy to help debug what's going on in your
      binary message data:

    @hl.ref(wd/'upickle/'test/'src/'upickle/'example/"ExampleTests.scala", Seq("\"msgToJson\"", ""))

    @p
      Note that such a conversion between MessagePack structs and JSON data is
      lossy: some MessagePack constructs, such as binary data, cannot be exactly
      represented in JSON and have to be converted to strings. Thus you should
      not rely on being able to round-trip data between JSON <-> MessagePack and
      getting the same thing back, although round tripping data between
      Scala-data-types <-> JSON and Scala-data-types <-> MessagePack should
      always work.

    @p
      Some of the differences between the ways things are serialized in
      MessagePack and JSON include:

    @ul
      @li
        Large Longs in JSON are represented as @code{ujson.Str}s if n > 2^53; in MessagePack,
        they are represented as @code{upack.Int64}s or @code{upack.UInt64}s
      @li
        @code{Array[Byte]}s in JSON are represented as lists of numbers; in MessagePack,
        they are represented as @code{upack.Binary}

    @p
      If you need to construct Scala case classes or other data types from your
      MessagePack binary data, you should directly use @code{upickle.default.readBinary}
      and @code{upickle.default.writeBinary}: these bypass the @code{upack.Msg}
      struct entirely for the optimal performance.

  @sect{Performance}
    @p
      The uPickle has a small set of benchmarks in @code{bench/} that tests
      reading and writing performance of a few common JSON libraries on a small,
      somewhat arbitrary workload. The numbers below show how many times each
      library could read/write a small data structure in 25 seconds (bigger
      numbers better). In some libraries, caching the serializers rather than
      re-generating them each read/write also improves performance: that effect
      can be seen in the @code{(Cached)} columns.

    @sect{JVM Case Class Serialization Performance}
      @p
        uPickle runs 30-50% faster than Circe for reads/writes, and ~200%
        faster than play-json.

      @table(cls := "pure-table", textAlign.right)
        @thead
          @tr
            @th{Library}
            @th{Reads}
            @th{Writes}
            @th{Reads (Cached)}
            @th{Write (Cached)}
        @tbody
          @tr
            @td{Play Json 2.9.2}
            @td{331}
            @td{296}
            @td{361}
            @td{309}
          @tr
            @td{Circe 0.13.0}
            @td{517}
            @td{504}
            @td{526}
            @td{502}
          @tr
            @td{upickle.default 1.3.0 (JSON Strings)}
            @td{809}
            @td{728}
            @td{822}
            @td{864}
          @tr
            @td{upickle.default 1.3.0 (JSON Array[Byte])}
            @td{761}
            @td{706}
            @td{774}
            @td{830}
          @tr
            @td{upickle.default 1.3.0 (MsgPack Array[Byte])}
            @td{1652}
            @td{1264}
            @td{1743}
            @td{1753}

      @p
        As you can see, uPickle's JSON serialization is pretty consistently
        ~50% faster than Circe for reads and writes, and 100-200% faster than
        Play-Json, depending on workload.

      @p
        uPickle's binary MessagePack backend is then another 100% faster than
        uPickle JSON.

      @p
        uPickle achieves this speed by avoiding the construction of an
        intermediate JSON AST: while most libraries parse from
        @code{String -> AST -> CaseClass}, uPickle parses input directly from
        @code{String -> CaseClass}. uPickle also provides a @code{ujson.Js} AST that
        you can use to manipulate arbitrary JSON, but @code{ujson.Js} plays no
        part in parsing things to case-classes and is purely for users who want
        to manipulate JSON.

    @sect{JS Case Class Serialization Performance}
      @p
        While all libraries are much slower on Scala.js/Node.js
        than on the JVM, uPickle runs
        4-5x as fast as Circe or Play-Json for reads and writes.
      @table(cls := "pure-table", textAlign.right)
        @thead
          @tr
            @th{Library}
            @th{Reads}
            @th{Writes}
            @th{Reads (Cached)}
            @th{Write (Cached)}
        @tbody
          @tr
            @td{Play Json 2.9.2}
            @td{64}
            @td{81}
            @td{66}
            @td{86}
          @tr
            @td{Circe 0.13.0}
            @td{98}
            @td{121}
            @td{99}
            @td{99}
          @tr
            @td{upickle.default 1.3.0 (JSON String)}
            @td{76}
            @td{40}
            @td{76}
            @td{44}
          @tr
            @td{upickle.default 1.3.0 (JSON Array[Byte]}
            @td{68}
            @td{107}
            @td{69}
            @td{112}
          @tr
            @td{upickle.default.web 1.3.0 (JSON String)}
            @td{349}
            @td{327}
            @td{353}
            @td{465}
          @tr
            @td{upickle.default 1.3.0 (MsgPack Array[Byte])}
            @td{85}
            @td{104}
            @td{85}
            @td{110}

    @p
      On Scala.js, uPickle's performance is comparable to othersl ike Play JSON or Circe.
      However, uPickle also exposes the @code{upickle.default.web} API, allowing you to
      use the JS runtime's built-in JSON parser to power serialization and deserialization.
      This ends up being 4-6x faster than the Scala-based JSON parsers of all the libraries
      compared (uPickle, Play-JSON, Circe)

    @p
      uJson is a fork of Erik Osheim's excellent [Jawn](https://github.com/non/jawn)
      JSON library, and inherits a lot of it's performance from Erik's work.

  @sect{Version History}
    @sect{3.0.0}
      @ul
        @li
          Greatly improved speed and runtime-time safety for Scala 3 macros.
          These were previously much slower than Scala 2, and are now of roughly
          identical performance @lnk("#445", "https://github.com/com-lihaoyi/upickle/pull/445")

        @li
          Fixed infinite compile-loop issue on Scala 3

        @li
          Support for the @hl.scala{deriving} keyword in Scala 3, on both @hl.scala{enum}s
          and @hl.scala{sealed trait}s @lnk("#453", "https://github.com/com-lihaoyi/upickle/pull/453")

        @li
          Ensured, that @code{ujson.Value}s behave properly as a direct target of reading
          and writing operations @lnk("#436", "https://github.com/com-lihaoyi/upickle/pull/436")

        @li
          @b{Updated geny dependency from 0.7.1 to 1.0.0. This breaks binary compatibility, hence we increased the major version number.}

        @li
          uPickle now applies Semantic Versioning and follows the SemVer spec

        @li
          @hl.scala{ujson.Bool} pattern matching is now exhaustive
          @lnk("#461", "https://github.com/com-lihaoyi/upickle/pull/461")

        @li
          Various library dependency updates

        @li
          Added readers and writers for the @hl.scala("java.lang") boxed versions
          of primitive types @lnk("#462", "https://github.com/com-lihaoyi/upickle/pull/462")

        @li
          Always use UTF-8 when reading JSON bytes regardless of JVM default charset
          @lnk("#464", "https://github.com/com-lihaoyi/upickle/pull/464")

    @sect{2.0.0}
      @ul
        @li
          @b{2.0.0 is a major breaking change in uPickle, including in the serialization
          format for many common data types (@hl.scala{Map}s, @hl.scala{case object}s,
          @hl.scala{Unit}, etc.). Please be careful upgrading and follow the instructions
          below.}

        @li
          If you are upgrading a system with multiple components from an earlier version
          of uPickle, please ensure you first upgrade every component to uPickle 1.6.0,
          which is forwards-compatible with the changes in uPickle 2.0.0. Only when every
          component is upgraded to 1.6.0 should you begin upgrading components to 2.0.0

        @li
          Once every component is upgraded to 1.6.0, they will be able to @i{read} both
          the old and new serialization formats, though they will
          still be @i{writing} the old format. You can then
          upgrade your components piecemeal to 2.0.0 without any incompatibility.

        @li
          uPickle 2.0.0 will @i{write} using the new serialization formats, but
          will be able to @i{read} both old and new formats indefinitely. Thus if you have
          data in storage using the old format, you do not need to migrate it to the new
          format, and it can remain as-is until it needs to be re-written for other reasons.

        @li
          @b{Major serialization changes are below}

        @li
          @hl.scala{case object}s are now serialized as literal strings
          @hl.scala{"foo.bar.Qux"} rather than JSON dictionaries
          @hl.scala("""{"$type": "foo.bar.Qux"}""")
          @lnk("#382", "https://github.com/com-lihaoyi/upickle/pull/382"). This also
          applies to Scala 3 Enums @lnk("378", "https://github.com/com-lihaoyi/upickle/pull/378")

        @li
          @hl.scala{Map}s with primitive keys can now be serialized
          as JSON dictionaries @hl.scala("""{"foo": "bar", "baz": "qux"}"""), rather than
          as nested tuples @hl.scala("""[["foo", "bar"], ["baz", "qux"]]""")
          @lnk("#381", "https://github.com/com-lihaoyi/upickle/pull/381"). This applies
          to numbers, booleans, strings, @code{java.util.UUID}s, @code{BigIntegers}, @code{BigDecimals},
          @code{scala.Symbol}s, @code{scala.concurrent.Duration}, and can be enabled for
          user-defined types. See @sect.ref{JSON Dictionary Formats} for more information
        @li
          @code{scala.Unit} now serializes as @hl.scala{null} rather than @hl.scala("{}")


    @sect{1.6.0}
      @ul
        @li
          Forwards compatibility for uPickle 2.x (@lnk("#385", "https://github.com/com-lihaoyi/upickle/pull/385")).
          This reduces the strictness of deserialization logic to allow parsing of both old and new
          formats: @code{Map}s can be deserialized from both JSON list-of-list and JSON dictionary
          formats, numbers can be deserialized from strings, and @code{Unit} can be deserialized from
          empty JSON dictionaries or nulls
        @li
          Automatic serialization of @hl.scala{case object}s has been removed, due to
          confusing bugs in how its implicit macro interacted with other implicit definitions.
          You now need to define @hl.scala{case object} serializers manually, via
          @hl.scala{implicit val rw: RW[MyCaseObject.type] = macroRW}

    @sect{1.5.0}
      @ul
        @li
          Support Scala-Native on Scala 3

    @sect{1.4.3}
      @ul 
         @li
           @code{MsgPackReader}: properly increment index in ext @lnk("#370", "https://github.com/com-lihaoyi/upickle/pull/370")

    @sect{1.4.2}
      @ul
         @li
           Bugfixes @lnk("#365", "https://github.com/com-lihaoyi/upickle/pull/365") @lnk("#366", "https://github.com/com-lihaoyi/upickle/pull/365")
    @sect{1.4.1}
      @ul
        @li
          BugFix: Util.parseLong (@lnk("#361", "https://github.com/lihaoyi/upickle/pull/361"))
        @li
          Implement visitFloat32, visitFloat64String for Byte/Short/Int/Long/Float/Double/Char (@lnk("#358", "https://github.com/lihaoyi/upickle/pull/358"))
    @sect{1.4.0}
      @ul
        @li
          Added support for large case classes with >64 fields
    @sect{1.3.11}
      @ul
        @li
          Publish for Scala 3.0.0-RC2
    @sect{1.3.8}
      @ul
        @li
          Minor performance tweaks
    @sect{1.3.7}
      @ul
        @li
          Removed @code{ArrayIndexOutOfBound}s from parsing and replaced them with @code{ParsingFailedException}s
    @sect{1.3.0}
      @ul
        @li
          Significant improvements (30-50%) to performance of reading and writing
          large JSON files, especially working with binary data in byte arrays or
          input streams.
    @sect{1.2.0}
      @ul
        @li
          Add optional `trace = true` parameter to `ujson.read`, `upack.read`,
          `upickle.default.read` and `upickle.default.readBinary` to provide better error
          messages when parsing or deserialization fails
    @sect{0.9.6}
      @ul
        @li
          Bump Geny dependency
        @li
          Add ability to parse from any @lnk("geny.Readable", "https://github.com/lihaoyi/geny#readable") data type, such as @code{java.io.InputStream}
    @sect{0.9.0}
      @ul
        @li
          Basic support for GADTs @lnk("#288", "https://github.com/lihaoyi/upickle/pull/288")
        @li
          @code{ujson.Value} and @code{upack.Msg} now support the
          @lnk("geny.Writable", "https://github.com/lihaoyi/geny#writable") interface
        @li
          Added new @code{upickle.default.writable} and @code{upickle.default.writableBinary},
          to serialize Scala data types via the
          @lnk("geny.Writable", "https://github.com/lihaoyi/geny#writable") interface

    @sect{0.8.0}
      @ul
        @li
          Improved performance by avoiding allocations in deserialization hot paths
          @lnk("#284", "https://github.com/lihaoyi/upickle/pull/284")
        @li
          Add null-safe cast helpers @lnk("#274", "https://github.com/lihaoyi/upickle/pull/274")
    @sect{0.7.5}
      @ul
        @li
          Support for Scala 2.13.0 final
    @sect{0.7.1}
      @ul
        @li
          Introduced new MessagePack backend for binary serialization! This is used
          via @code{upickle.default.writeBinary}/@code{upickle.default.readBinary},
          or via the standalone @code{upack.read}/@code{upack.write} package.
          Binary serialization typically is 50-100% faster than JSON when running
          on the JVM.

        @li
          @code{ujson.Js.Value}, @code{ujson.Js.Obj}, etc. are now just
          @code{ujson.Value}, @code{ujson.Obj}

        @li
          Small @code{Long} 64-bit integers are now read/written as JSON numbers
          by default; only large values which cannot be precisely stored in
          @code{Double}-precision floating point (n > 2^53) are written as strings.
          You can revert to the old behavior via a @sect.ref{Custom Configuration}
          with:
          @hl.scala
            override implicit val LongWriter = new Writer[Long] {
              def write0[V](out: Visitor[_, V], v: Long) = out.visitInt64(v, -1)
            }

        @li
          @code{upickle.json.*} and @code{upickle.Js.*} have been removed (use
          @code{ujson.*}.

    @sect{0.6.7}
      @ul
        @li
          Added the @hl.scala{escapeUnicode: Boolean = false} flag to @code{ujson.Js#Render}
          and @code{ujson.Renderer}; pass in @hl.scala{false} to rrender unicode
          characters verbatim rather than escaping them.
    @sect{0.6.6}
      @ul
        @li
          Fix ability to construct single-element @code{Js.Obj} values without
          explicitly wrapping values [#230](https://github.com/lihaoyi/upickle/issues/230)
        @li
          Add @code{JsValue#bool} helper [#227](https://github.com/lihaoyi/upickle/pull/223)
          for extracting boolean values
    @sect{0.6.5}
      @ul
        @li
          Add ability to update a JSON dictionary key or array item in place
          via @hl.scala{json(0)("myFieldA") = _.num + 100}
    @sect{0.6.4}
      @ul
        @li
          Fix uJson direct dependency artifact naming
    @sect{0.6.3}
      @ul
        @li
          Added @code{ujson.copy} helper
        @li
          Added implicit constructors for @code{ujson.Js.Obj} and @code{Arr}
    @sect{0.6.2}
      @ul
        @li
          Fix conversion of case classes to other case classes via upickle.default.transform
    @sect{0.6.0}
      @ul
        @li
          ~3x faster than 0.5.1; uPickle now has the best @sect.ref{Performance}
          out of any of the commonly-used Scala JSON libraries

        @li
          The old @code{upickle.Js} JSON AST and @lnk("non/jawn", "https://github.com/non/jawn")
          dependency have been combined into the @sect.ref{uJson} standalone library.
          uJson provides high-performance streaming JSON processing that lets uPickle
          parse input strings directly to case classes without an intermediate AST.
        @li
          @code{upickle.Js} objects are now mutable, and had some implicits added
          to make @sect.ref{Construction} less awkward.
        @li
          The set of @sect.ref{Common Operations} and @sect.ref{JSON Utilities}
          has been fleshed out: you now have convenient helpers for streaming
          JSON re-formatting or validation, and can read from arbitrary inputs
          (strings, byte-arrays, files, ...) using the same @code{upickle.default.read}
          call
        @li
          The way you write @sect.ref{Custom Picklers} and @sect.ref{Custom Configuration}
          has changed. The new ways are hopefully more intuitive,
          allow much better back-end performance, and should be just as flexible
          as the old way, but if you have custom picklers/configurations in your
          code you'll have to go update them.
        @li
          uPickle now supports parsing to (and serializing) @sect.ref{Other ASTs},
          from libraries such as Circe, Argonaut, Json4s or Play-Json. You can now
          also do high-performance/streaming @sect.ref{Cross-Library Conversions}
          to transform from one library's AST to another without any intermediate
          structures.

    @sect{0.5.1}
      @ul
        @li
          Strip out automatic "deep" case-class serialization: you must now
          define a serializer for each case class you want to deal with, preferably
          in the companion object
        @li
          Upgrade Jawn version to 0.11.0, add helpers in @code{ujson} to
          parse JSON coming from files.
        @li
          New @code{ujson.writeTo} function for serializing JSON directly
          to a @code{java.io.Writer}, rather than creating a @code{String}

        @li
          @code{ujson.write} now takes an optional `sortKeys` flag, if
          you want the JSON dictionaries to rendered in a standardized order

        @li
          Drop support fo Scala 2.10

    @sect{0.4.3}
      @ul
        @li
          Support for @hl.scala{BigInt} and @hl.scala{BigDecimal},
          thanks to @lnk("Jisoo Park", "https://github.com/guersam")
        @li
          @code{Js.Value}s are now serializable, thanks to
          @lnk("Felix Dietze", "https://github.com/fdietze")
        @li
          Made it easy to write @sect.ref{Manual Sealed Trait Picklers}
          in order to work around problems with SI-7046
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.2")
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.1")
    @sect{0.4.0}
      @ul
        @li
          Allow custom handling for JSON @hl.scala{null}s via a @sect.ref{Custom Configuration}
        @li
          Made @hl.scala{upickle.key} a @hl.scala{case class}
        @li
          Remove unnecessary dependency of @hl.scala{derive} on default arguments #143
        @li
          Fixed derivation allowing Caching Picklers in a @hl.scala{case class}'s companion object, potentially speeding up compilation times and runtimes
    @sect{0.3.9}
      @ul
        @li
          Add @hl.scala{.arr: Seq[Js.Value]}, @hl.scala{.obj: Map[String, Js.Value]}, @hl.scala{.str: String} and @hl.scala{.num: Double} helper methods on @hl.scala{Js.Value} to simplify usage as a simple JSON tree.
        @li
          @hl.scala{Invalid.Json} and @hl.scala{Invalid.Data} now have better exception messages by default, which should simplify debugging
        @li
          Some usages should compile faster due to fiddling with implicits (#138)
    @sect{0.3.8}
      @ul
        @li
          Tweaks to PPrint
    @sect{0.3.7}
      @ul
        @li
          You can now pass in an @hl.scala{indent} parameter to @hl.scala{upickle.default.write} in order to format/indent the JSON nicely across multiple lines
        @li
          Derivation based on sealed abstract classes works, in addition to traits (#104), thanks to @a("Voltir", href:="https://github.com/Voltir")
        @li
          Fix non-deterministic failure due to improperly implemented @code{equals}/@code{hashCode} in macro (#124), thanks to @a("Voltir", href:="https://github.com/lihaoyi/upickle-pprint/issues/124")
        @li
          Slightly improve hygiene of uPickle/PPrint macro expansion
        @li
          uPickle de-serialization failures should no longer throw @code{MatchErrors} (#101)
        @li
          Using case-class-derived @code{Reader}s/@code{Writer}s should no longer fail in class @code{extends} clauses (#108)
        @li
          @code{Float.NaN} and @code{Double.NaN} are now properly handled (#123)
        @li
          Provided an example of a @sect.ref{Custom Configuration} being used to @code{snake_case} case-class fields during serialization/de-serialization (#120)

    @sect{0.3.6}
      @ul
        @li
          Fix more bugs in PPrint derivation
    @sect{0.3.5}
      @ul
        @li
          Fix some bugs in PPrint derivation
    @sect{0.3.4}
      @ul
        @li
          Remove unnecessary shapeless dependency
    @sect{0.3.3}
      @ul
        @li
          Fix more edge cases to avoid diverging implicits
    @sect{0.3.2}
      @ul
        @li
          Fix more edge cases around typeclass derivation: #94, #95, #96
        @li
          Don't get tripped up by custom Apply methods: #48
    @sect{0.3.1}
      @ul
        @li
          Fixed edge cases around typeclass derivation

    @sect{0.3.0}
      @ul
        @li
          Top-to-bottom rewrite of type-class derivation macros. Much faster, more reliable, etc.. Still one or two cases where it misbehaves, but much fewer than before. Extracted it into the @hl.scala{derive} subproject
        @li
          Force users to choose between @hl.scala{import upickle.default._} which now renders sealed trait hierarchies as dictionaries with a @hl.scala{$type} attribute, and @hl.scala{import upickle.legacy._} which does the old-style array-wrapper.
        @li
          You can also now create your own custom subclass of @hl.scala{upickle.Api} if you wish to customize things further, e.g. changing the type-attribute or changing the rendering of case classes.

    @sect{0.2.8}
      @ul
        @li
          Support for @hl.scala{java.util.UUID}, which are serialized as strings in the standard format

    @sect{0.2.7}
      @ul
        @li
          Re-published for Scala.js 0.6.1

    @sect{0.2.6}
      @ul
        @li
          @hl.scala{'Symbol}s are now read/write-able by default
        @li
          Added lots of warnings for common issues
        @li
          @hl.scala{Map[String, V]} now pickles to a JSON dictionary @hl.scala(""""key": "value", ...}"""). @hl.scala{Map[K, V]} for all other @hl.scala{K != String} are unchanged
        @li
          Source maps now point towards a reasonabel place on Github


    @sect{0.2.5}
      @ul
        @li
          Fixed [#23](https://github.com/lihaoyi/upickle/issues/23): self-recursive data structures are now supported.
        @li
          Fixed [#18](https://github.com/lihaoyi/upickle/issues/18): you can now auto-pickle classes in objects that originated from traits that were mixed in.


    @sect{0.2.4}
      @ul
        @li
          Support reading and writing @hl.scala{null}
        @li
          Fixed Reader/Writer macros for single-class sealed hierarchies
        @li
          Used @hl.scala{CanBuildFrom} to serialize a broader range of collections

    @sect{0.2.3}
      @ul
        @li
          Added a pickler for @hl.scala{Unit}/@hl.scala{()}

    @sect{0.2.2}
      @ul
        @li
          Swapped over from the hand-rolled parser to using @hl.scala{Jawn}/@hl.scala{JSON.parse} on the two platforms, resulting in a 10-15x speedup for JSON handling.
        @li
          Renamed @hl.scala("""Js.{String, Object, Array, Number}""") into @hl.scala("""Js.{Str, Obj, Arr, Num}"""), and made @hl.scala{Js.Arr} and @hl.scala{Js.Obj} use varargs, to allow for better direct-use.
        @li
          Documented and exposed JSON API for direct use by users of the library.

    @sect{0.2.1}
      @ul
        @li
          Improved error messages for unpickle-able types
        @li
          ScalaJS version now built against 0.5.3

    @sect{0.2.0}
      @ul
        @li
          Members of sealed trait/class hierarchies are now keyed with the fully-qualified name of their class, rather than an index, as it is less likely to change due to adding or removing classes
        @li
          Members of sealed hierarchies and parameters now support a @hl.scala{upickle.key("...")} annotation, which allows you to override the default key used (which is the class/parameter name) with a custom one, allowing you to change the class/param name in your code while maintaining compatibility with serialized structures
        @li
          Default parameters are now supported: they are used to substitute missing keys when reading, and cause the key/value pair to be omitted if the serialized value matches the default when writing
        @li
          Missing keys when deserializing case classes now throws a proper @hl.scala{Invalid.Data} exception
        @li
          @hl.scala{object}s are now serialized as @hl.scala("""{}""") rather than @hl.scala{[]}, better matching the style of case classes
        @li
          0-argument case classes, previously unsupported, now serialize to @hl.scala("""{}""") the same way as @hl.scala{object}s
        @li
          Fixed a bug that was preventing multi-level sealed class hierarchies from being serialized due to a compilation error
        @li
         Fixed a bug causing case classes nested in other packages/objects and referred to by their qualified paths to fail pickling
        @li
          Tightened up error handling semantics, swapping out several @hl.scala{MatchError}s with @hl.scala{Invalid.Data} errors

    @sect{0.1.7}
      @ul
        @li
          Cleaned up the external API, marking lots of things which should have been private private or stuffing them in the @hl.scala{Internals} namespace
        @li
          Organized things such that only a single import @hl.scala{import upickle._} is necessary to use the library

    @sect{0.1.6}
      @ul
        @li
          Tuples and case classes now have implicit picklers up to an arity limit of 22.
        @li
          Case classes now serialize as JSON dictionaries rather than as lists.

    @sect{0.1.5}
      @ul
        @li
          Simple case classes and case class hierarchies are now auto-serializable view Macros. No need to define your own implicit using @hl.scala{Case0ReadWriter} anymore!

    @sect{0.1.4}
      @ul
        @li
          Serialize numbers as JSON numbers instead of Strings.

    @sect{0.1.3}
      @ul
        @li

          Specification of the exception-throwing behavior: instead of failing with random @hl.scala{MatchError}s or similar, parse failures now are restricted to subclasses @hl.scala{upickle.Invalid} which define different failure modes.
