
@import Main._


@def lnk(txt: String, url: String) = a(txt, href:=url)
@val exampleTests = wd/'upickle/'test/"src"/'upickle/'example/"ExampleTests.scala"
@val jvmExampleTests = wd/'upickle/'test/"src-jvm"/'upickle/'example/"JvmExampleTests.scala"
@val macroTests = wd/'upickle/'test/'src/'upickle/"MacroTests.scala"

@val optionsAsNullTests =  wd/'upickle/'test/"src"/'upickle/'example/"OptionsAsNullTests.scala"


@a(
  href := "https://github.com/lihaoyi/upickle-pprint",
  img(
    position.absolute,
    top := 0,
    right := 0,
    border := 0,
    src := "https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67",
    alt := "Fork me on GitHub",
    data.`canonical-src` := "https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
  )
)

@sect("ÂµPickle 0.6.4")
  @div(display.flex, alignItems.center, flexDirection.column)
    @div
      @a(href := "https://gitter.im/lihaoyi/upickle")(
        img(src := "https://badges.gitter.im/Join%20Chat.svg")
      )
      @span(" ")
      @a(href := "https://www.patreon.com/lihaoyi")(
        img(src := "https://img.shields.io/badge/patreon-sponsor-ff69b4.svg")
      )

  @p
    uPickle (pronounced micro-pickle) is a lightweight JSON serialization library
    for Scala. It's key features are:
  @ul
    @li
      @sect.ref("Getting Started", "Simple to use"), with nice human-readable JSON output
    @li
      Very high @sect.ref{Performance}; faster than
      @lnk("Play-Json", "https://github.com/playframework/play-json"),
      @lnk("Circe", "https://github.com/circe/circe"), or
      @lnk("Argonaut", "https://github.com/argonaut-io/argonaut")
      by a large margin
    @li
      Simple & easy to understand @sect.ref("uJson", "JSON Processing API"),
      that should be instantly familiar to anyone whose processed JSON in
      Python, Ruby, or Javascript
    @li
      Flexible and easily @sect.ref("Customization", "customizable")
    @li
      Zero dependencies; can be included in any project without worrying about
      conflicts
    @li
      @sect.ref("ScalaJS") support, allowing transfer of structured data
      between the JVM and Javascript

  @sect{Getting Started}
    @p
      Add the following to your SBT config:
    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "upickle" % "0.6.4"


    @p
      And then you can immediately start writing and reading common Scala
      objects to strings:

    @hl.ref(exampleTests, Seq("'simple", ""))

    @sect{ScalaJS}
      @p
        For ScalaJS applications, use this dependencies instead:
      @hl.scala
        libraryDependencies += "com.lihaoyi" %%% "upickle" % "0.6.4"
      @p
        Other than that, everything is used the same way. upickle-0.6.4
        is only compatible with ScalaJS 0.6.x.

    @sect{Scala 2.10}
      @p

        uPickle does not support Scala 2.10; only 2.11 and 2.12 are supported

  @sect{Basics}
    @sect{Builtins}
      @p
        This is a non-comprehensive list of what the most commonly-used types
         pickle to using uPickle. To begin, let's import upickle

      @hl.scala
        import upickle.default._

      @p
        Booleans are serialized as JSON booleans

      @hl.ref(exampleTests, Seq("'more", "'booleans", ""))

      @p
        Numbers are serialized as JSON numbers

      @hl.ref(exampleTests, Seq("'more", "'numbers", ""))

      @p
        Except for @hl.scala{Long}s, which too large for Javascript. These are
        serialized as JSON Strings, keeping the interchange format compatible
         with the browser's own JSON parser, which provides the best
          performance in Scala.js

      @hl.ref(exampleTests, Seq("'more", "'longs", ""))

      @p
        Special values of @hl.scala{Double}s and @hl.scala{Float}s are also
        serialized as Strings

      @hl.ref(exampleTests, Seq("'more", "'specialNumbers", ""))



      @p
        Both @hl.scala{Char}s and @hl.scala{String}s are serialized as Strings

      @hl.ref(exampleTests, Seq("'more", "'charStrings", ""))

      @p
        @code{Array}s and most immutable collections are serialized as JSON lists

      @hl.ref(exampleTests, Seq("'more", "'seqs", ""))

      @p
        @code{Option}s are serialized as JSON lists with 0 or 1 element

      @hl.ref(exampleTests, Seq("'more", "'options", ""))


      @p
        Tuples of all sizes (1-22) are serialized as heterogenous JSON lists

      @hl.ref(exampleTests, Seq("'more", "'tuples", ""))

      @p
        Case classes of sizes 1-22 are serialized as JSON dictionaries with the
        keys being the names of each field.
        To begin with, you need to define a serializer in the Case Class's
        companion object:

      @hl.scala
        import upickle.default.{ReadWriter => RW, macroRW}

      @p
        After that, you can begin serializing that case class.

      @hl.ref(exampleTests, Seq("object Simple", ""))
      @hl.ref(exampleTests, Seq("'more", "'caseClass", ""), "        }")

      @p
        Sealed hierarchies are serialized as tagged values, the serialized
        object tagged with the full name of the instance's class:

      @hl.ref(exampleTests, Seq("object Sealed", ""))
      @hl.ref(exampleTests, Seq("'more", "'sealed", ""), "  }")

      @p
        Serializability is recursive; you can serialize a type only if all
        its members are serializable. That means that collections, tuples and
        case-classes made only of serializable members are themselves serializable

      @hl.ref(exampleTests, Seq("object Recursive", ""))
      @hl.ref(exampleTests, Seq("'more", "'recursive", ""), "  }")

      @p

        Nulls serialize into JSON nulls, as you would expect

      @hl.ref(exampleTests, Seq("'more", "'null", ""), "  }")

      @p
        uPickle only throws exceptions on unpickling; if a pickler is
        properly defined, serializing a data structure to a @hl.scala{String}
        should never throw an exception.

    @sect{Read/Writing Other Things}

      @p
        Apart from reading & writing @code{java.lang.String}s, allows you to easily
        read from alternate sources such as @code{CharSequence}s, @code{Array[Byte]}s,
        @code{java.io.File}s and @code{java.nio.file.Path}s:

      @hl.ref(exampleTests, Seq("'sources", ""), "  }")
      @hl.ref(jvmExampleTests, Seq("'sources", ""), "  }")

      @p
        Reading from large files is automatically streamed so you do not read the
        entire file into memory. You can use @code{writeTo} to serialize your
        data to an arbitrary @code{java.io.Writer}/@code{java.io.OutputStream}:
        this can be streamed directly to files or over the network without having
        to accumulate the serialized JSON in memory.

    @sect{Defaults}

      @p
        If a field is missing upon deserialization, uPickle uses the default
        value if one exists

      @hl.ref(exampleTests, Seq("'defaults", "'reading", ""), "  }")

      @p

        If a field at serialization time has the same value as the default,
         uPickle leaves it out of the serialized blob

      @hl.ref(exampleTests, Seq("'defaults", "'writing", ""), "  }")

      @p

        This allows you to make schema changes gradually, assuming you have
        already pickled some data and want to add new fields to the case classes
        you pickled. Simply give the new fields a default value (e.g.
        @hl.scala{""} for Strings, or wrap it in an @hl.scala{Option[T]} and
        make the default @hl.scala{None}) and uPickle will happily read the
        old data, filling in the missing field using the default value.

    @sect{Supported Types}
      @p
        Out of the box, uPickle supports writing and reading the following types:
      @ul
        @li
          @hl.scala{Boolean}, @code{Byte}, @code{Char}, @code{Short},
          @code{Int}, @code{Long}, @code{Float}, @code{Double}
        @li
          @code{Tuple}s from 1 to 22
        @li
          Immutable @code{Seq}, @code{List}, @code{Vector}, @code{Set},
          @code{SortedSet}, @code{Option}, @code{Array}, @code{Map}s, and all
          other collections with a reasonable @hl.scala{CanBuildFrom} implementation
        @li
          @code{Duration}, @code{Either}
        @li
          Stand-alone @hl.scala{case class}es and @hl.scala{case object}s, and
           their generic equivalents,
        @li
          Non-generic @hl.scala{case class}es and @hl.scala{case object}s that
          are part of a @hl.scala{sealed trait} or @hl.scala{sealed class} hierarchy
        @li
          @hl.scala{sealed trait} and @hl.scala{sealed class}es themselves,
           assuming that all subclasses are picklable
        @li
          @code{UUID}s
        @li
          @hl.scala{null}
      @p
        Readability/writability is recursive: a container such as a @code{Tuple}
        or @hl.scala{case class} is only readable if all its contents are
         readable, and only writable if all its contents are writable. That means
          that you cannot serialize a @hl.scala{List[Any]}, since uPickle doesn't
           provide a generic way of serializing @code{Any}. Case classes are only
           serializable up to 22 fields.

      @p
        Case classes are serialized using the @hl.scala{apply} and
        @hl.scala{unapply} methods on their companion objects. This means that
        you can make your own classes serializable by giving them companions
         @hl.scala{apply} and @hl.scala{unapply}. @hl.scala{sealed} hierarchies
         are serialized as tagged unions: whatever the serialization of the
         actual object, together with the fully-qualified name of its class, so
          the correct class in the sealed hierarchy can be reconstituted later.

      @p
        That concludes the list of supported types. Anything else is not supported
        by default, but you can add support using @sect.ref{Custom Picklers}

    @sect{Common Operations}
      @p
        The following common operations are available on any uPickle module,
        e.g. @code{upickle.default} or @code{upickle.legacy}:

      @hl.ref(wd/'upickle/'src/'upickle/"Api.scala", Seq("trait Api", ""), "// End Api")

  @sect{Customization}
    @sect{Custom Picklers}
      @hl.ref(exampleTests, Seq("'mapped", "'simple", ""), "}")

      @p
        You can use the @code{readwriter[T].bimap[V]} function to create a pickler
        that reads/writes a type @code{V}, using the pickler for type @code{T},
        by providing a conversion function between them.

      @p
        The type you are @code{.bimap}ing to doesn't need to be a case class,
        or be pickleable in any way, as long as the type you are
        @code{.bimap}ing from is pickleable. The following example demonstrates
        using @code{.bimap} to define a serializer for non-case Scala class

      @hl.ref(exampleTests, Seq("object Custom2", ""))

      @p
        Note that when writing custom picklers, it is entirely up to you to get
        it right, e.g. making sure that an object that gets round-trip
        pickled/unpickled comes out the same as when it started.

      @p
        Lastly, if you want more control over exactly how something is serialized,
        you can use @code{readwriter[Js.Value].bimap} to give yourself access to
        the raw JSON AST:

      @hl.ref(exampleTests, Seq("'mapped", "'Js", ""))

    @sect{Custom Keys}
      @p

        uPickle allows you to specify the key that a field is serialized with
        via a @hl.scala{@@key} annotation


      @hl.ref(exampleTests, Seq("object Keyed", ""))
      @hl.ref(exampleTests, Seq("'keyed", "'attrs", ""))

      @p

        Practically, this is useful if you want to rename the field within your
        Scala code while still maintaining backwards compatibility with
        previously-pickled objects. Simple rename the field and add a
        @hl.scala{@@key("...")} with the old name so uPickle can continue to work
        with the old objects correctly.
      @p
        You can also use @hl.scala{@@key} to change the name used when pickling
        the case class itself. Normally case classes are pickled without their
        name, but an exception is made for members of sealed hierarchies which
        are tagged with their fully-qualified name. uPickle allows you to use
        @hl.scala{@@key} to override what the class is tagged with:

      @hl.ref(exampleTests, Seq("object KeyedTag", ""))
      @hl.ref(exampleTests, Seq("'keyed", "'tag", ""))



      @p
        This is useful in cases where:
      @ul
        @li
          you wish to rename the class within your Scala code, or move it to a
          different package, but want to preserve backwards compatibility with
          previously pickled instances of that class
        @li
          you try to tackle the resource issue (bandwidth, storage, CPU) because
          FQNs might get quite long

    @sect{Custom Configuration}
      @p
        Often, there will be times that you want to customize something on a
        project-wide level. uPickle provides hooks in letting you subclass the
        @hl.scala{upickle.Api} trait to create your own bundles apart from the
        in-built @hl.scala{upickle.default} and @hl.scala{upickle.legacy}. The
        following example demonstrates how to customize a bundle to
        automatically @code{snake_case} all dictionary keys.

        @hl.ref(exampleTests, Seq("'snakeCase", ""))

      @p
        If you are using uPickle to convert JSON from another source into Scala
        data structures, you can also configure it to map @hl.scala{Option[T]}s
        to @code{null}s when the option is @code{None}:

      @hl.ref(optionsAsNullTests, "object OptionPickler", "// end_ex")

      @p
        This custom configuration allows you to treat @hl.scala{null}s as
        @hl.scala{None}s and anything else as @hl.scala{Some(...)}s. Simply
        @hl.scala{import OptionPickler._} instead of the normal uPickle import
        throughout your project and you'll have the customized reading/writing
        available to you.

  @sect{Limitations}

    @p
      uPickle doesn't currently support:
    @ul
      @li
        Circular object graphs
      @li
        Reflective reading and writing
      @li
        Read/writing of untyped values e.g. @code{Any}
      @li
        Read/writing arbitrarily shaped objects
      @li
        Read/writing case classes with multiple parameter lists.
    @p
      Most of these limitations are inherent in the fact that ScalaJS does not
      support reflection, and are unlikely to ever go away. In general, uPickle
      by default can serialize statically-typed, tree-shaped, immutable data
      structures. Anything more complex requires @sect.ref{Custom Picklers}

    @sect{Manual Sealed Trait Picklers}
      @p
        Due to a bug in the Scala compiler SI-7046, automatic sealed trait
        pickling can fail unpredictably. This can be worked around by instead
        using the @code{macroRW} and @code{merge} methods to manually specify
        which sub-types of a sealed trait to consider when pickling:
    
      @hl.ref(macroTests, "sealed trait TypedFoo", "// End TypedFoo")

  @sect{uJson}

    @p
      uJson is uPickle's JSON library, which can be used to easily
      manipulate JSON source and data structures without converting them into
      Scala case-classes. This all lives in the @code{ujson} package. Unlike
      many other Scala JSON libraries that come with their own zoo of new
      concepts, abstractions, and techniques, uJson has a simple & predictable
      JSON API that should be instantly familiar to anyone coming from
      scripting languages like Ruby, Python or Javascript.

    @p
      uJson comes bundled with uPickle, or can be used stand-alone via the
      following package coordinates:

    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "ujson" % "0.6.4"

    @sect{Construction}
      @p
        You can use @code{ujson} to conveniently construct JSON blobs, either
        programmatically:
      @hl.ref(exampleTests, Seq("'json", "'construction", ""), "}")

      @p
        Or parsing them from strings, byte arrays or files:

      @hl.ref(exampleTests, Seq("'json", "'simple", ""), "}")

      @p
        @code{ujson.Js} ASTs are mutable, and can be modified before being re-serialized
        to strings:

      @hl.ref(exampleTests, Seq("'json", "'mutable", ""), "}")

      @p
        You can also use the `_` shorthand syntax to update a JSON value in
        place, without having to duplicate the whole path:

      @hl.ref(exampleTests, Seq("'json", "'update", ""), "}")

      @p
        case classes or other Scala data structures can be converted to
        @code{ujson.Js} ASTs using @code{upickle.default.writeJs}, and the
        @code{ujson.Js} ASTs can be converted back using @code{upickle.default.readJs}
        or plain @code{upickle.default.read}:

      @hl.ref(exampleTests, Seq("'json", "'intermediate", ""), "}")

    @sect{JSON Utilities}
      @p
        uJson comes with some convenient utilities on the `ujson` package:

      @hl.ref(wd/'ujson/'src/'ujson/"package.scala", Seq("package object ujson", ""), "// End ujson")

    @sect{Transformations}
      @p
        uJson allows you seamlessly convert between any of the following forms
        you may find your JSON in:

      @ul
        @li
          Case classes & Scala data-types
        @li
          @code{ujson.Js} ASTs
        @li
          @code{String}s
        @li
          @code{CharSequence}s
        @li
          @code{Array[Byte]}s
        @li
          Third-party JSON ASTs (Argonaut, Circe, Json4s, Play-Json)
      @p
        This is done using the @code{ujson.transform(source, dest)} function:

      @hl.ref(exampleTests, Seq("'json", "'misc", ""), "}")

      @p
        All transformations from A to B using @code{ujson.transform} happen
        in a direct fashion: there are no intermediate JSON ASTs being generated,
        and performance is generally very good.

      @p
        You can use @code{ujson.transform} to validate JSON in a streaming
        fashion:

      @hl.ref(exampleTests, Seq("'json", "'validate", ""), "}")

      @p
        The normal @code{upickle.default.read/write} methods to serialize Scala
        data-types is just shorthand for ujson.transform,
        using a @code{upickle.default.writable(foo)} as the source or a
        @code{upickle.default.reader[Foo]} as the destination:

      @hl.ref(exampleTests, Seq("'json", "'upickleDefault", ""), "}")

    @sect{Other ASTs}
      @p
        uJson does not provide any other utilities are JSON that other libraries
        do: zippers, lenses, combinators, etc.. However, uJson can be used to
        seamlessly convert between the JSON AST of other libraries! This means
        if some other library provides a more convenient API for some kind of
        processing you need to do, you can easily parse to that library's AST,
        do whatever you need, and convert back after.

      @p
        As mentioned earlier, conversions are fast and direct, and happen
        without creating intermediate JSON structures in the process. The
        following examples demonstrate how to use the conversion modules for
        @lnk("Argonaut", "http://argonaut.io/doc/"),
        @lnk("Circe", "https://github.com/circe/circe"),
        @lnk("Json4s", "https://github.com/json4s/json4s"), and
        @lnk("Play Json", "https://github.com/playframework/play-json").
      @p
        Each example parses JSON from a string into that particular library's
        JSON AST, manipulates the AST using that library, un-pickles it into
        Scala data types, then serializes those data types first into that
        library's AST then back to a st.ring

      @sect{Argonaut}
        @b{Maven Coordinates}

        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-argonaut" % "0.6.4"

        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("'argonaut", ""), "}")

      @sect{Circe}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-circe" % "0.6.4"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("'circe", ""), "}")

      @sect{Play-Json}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-play" % "0.6.4"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("'play", ""), "}")

      @sect{Json4s}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-json4s" % "0.6.4"
        @b{Usage}
        @hl.ref(jvmExampleTests, Seq("'json4s", ""), "}")

      @sect{Cross-Library Conversions}
        @p
          uJson lets you convert between third-party ASTs efficiently and with
          minimal overhead: uJson converts one AST to the other directly
          and without any temporary compatibility data structures. The following
          example demonstrates how this is done: we parse a JSON string using
          Circe, perform some transformation, convert it to a Play-Json AST,
          perform more transformations, and finally serialize it back to a
          String and check that both transformations were applied:

        @hl.ref(jvmExampleTests, Seq("'crossAst", ""), "}")

  @sect{Performance}
    @p
      The uPickle has a small set of benchmarks in @code{bench/} that tests
      reading and writing performance of a few common JSON libraries on a small,
      somewhat arbitrary workload. The numbers below show how many times each
      library could read/write a small data structure in 25 seconds (bigger
      numbers better). In some libraries, caching the serializers rather than
      re-generating them each read/write also improves performance: that effect
      can be seen in the @code{(Cached)} columns.

    @sect{JVM Case Class Serialization Performance}
      @p
        uPickle runs 30-50% faster than Circe for reads/writes, and ~200%
        faster than play-json.

      @table(cls := "pure-table", textAlign.right)
        @thead
          @tr
            @th{Library}
            @th{Reads}
            @th{Writes}
            @th{Reads (Cached)}
            @th{Write (Cached)}
        @tbody
          @tr
            @td{Jackson-Scala}
            @td{2,038,770}
            @td{11,324,495}
            @td
            @td
          @tr
            @td{Play Json}
            @td{  987,940}
            @td{1,357,490}
            @td{1,122,132}
            @td{1,574,340}
          @tr
            @td{Circe}
            @td{2,360,411}
            @td{2,139,692}
            @td{2,732,585}
            @td{2,172,389}
          @tr
            @td{upickle.default}
            @td{3,135,576}
            @td{3,496,939}
            @td{3,706,736}
            @td{4,392,758}
          @tr
            @td{upickle.legacy}
            @td{2,315,402}
            @td{2,526,501}
            @td{3,889,198}
            @td{4,285,537}

      @p
        As you can see, uPickle is pretty consistently ~30% faster than Circe
        for reads and ~50% faster for writes. It is also faster than
        Jackson-Scala on reads by a similar margin, although somehow Jackson-Scala
        has write performance that far outstrips everyone else. uPickle is 100-200%
        faster than Play-Json, depending on workload

      @p
        uPickle achieves this speed by avoiding the construction of an
        intermediate JSON AST: while most libraries parse from
        @code{String -> AST -> CaseClass}, uPickle parses input directly from
        @code{String -> CaseClass}. uPickle also provides a @code{ujson.Js} AST that
        you can use to manipulate arbitrary JSON, but @code{ujson.Js} plays no
        part in parsing things to case-classes and is purely for users who want
        to manipulate JSON.

    @sect{JVM AST Serialization Performance}
      @p
        If you benchmark the various libraries parsing from @code{String -> AST},
        instead of @code{String -> CaseClass}, uPickle's numbers are in line with
        everyone else's:

      @table(cls := "pure-table", textAlign.right)
        @thead
          @tr
            @th{Library}
            @th{AST Reads}
            @th{AST Writes}
        @tbody
          @tr
            @td{uPickle}
            @td{2,890,396}
            @td{4,055,356}
          @tr
            @td{Play Json}
            @td{2,946,590}
            @td{3,224,360}
          @tr
            @td{Circe}
            @td{5,910,122}
            @td{6,186,478}
          @tr
            @td{Argonaut}
            @td{2,882,782}
            @td{3,271,907}
          @tr
            @td{Json4s Native}
            @td{3,214,664}
            @td{1,239,398}
      @p
        One thing to note is that uPickle's AST-serialization performance is
        significantly worse than uPickle's CaseClass-serialization performance,
        for both reads (2,890,396 vs 3,706,736) and writes
        (4,392,758 vs 4,055,356) when the serializers are cached. This may seem
        surprising, but it makes sense when you realize that constructing a tree
        of dictionaries/arraybuffers (which is what an AST is) should be slower
        than constructing a tree of plain-old-java-objects.

    @sect{JS Case Class Serialization Performance}
      @p
        While all libraries are much slower on Scala.js/Node.js
        than on the JVM, uPickle runs
        4-5x as fast as Circe or Play-Json for reads and writes.
      @table(cls := "pure-table", textAlign.right)
        @thead
          @tr
            @th{Library}
            @th{Reads}
            @th{Writes}
            @th{Reads (Cached)}
            @th{Write (Cached)}
        @tbody
          @tr
            @td{Play Json}
            @td{117,181}
            @td{194,582}
            @td{138,665}
            @td{253,164}
          @tr
            @td{Circe}
            @td{132,519}
            @td{441,906}
            @td{151,030}
            @td{644,901}
          @tr
            @td{upickle.default}
            @td{613,727}
            @td{1,041,798}
            @td{862,280}
            @td{1,548,753}
          @tr
            @td{upickle.legacy}
            @td{541,242}
            @td{913,455}
            @td{874,563}
            @td{1,469,347}
          @tr
            @td{upickle.default.web}
            @td{518,840}
            @td{952,393}
            @td{912,521}
            @td{1,731,286}
          @tr
            @td{upickle.legacy.web}
            @td{500,202}
            @td{872,095}
            @td{782,801}
            @td{1,568,826}

    @p
      Apart from the huge difference between uPickle and it's alternatives,
      this Scala.js/Node.js benchmark also shows a much larger effect for caching
      the picklers: 80-100% speedup. It seems likely that Scala.js/Node.js just 
      isn't as good at optimizing away the overhead of temporary/throwaway
      data-structures, whether they're intermediate-ASTs or temporary-pickler-instances.
    @p
      Another thing of note is the @code{.web} entries; these are benchmarking
      uPickle using the Node.js @code{JSON.parse} and @code{JSON.stringify} 
      builtin functions, rather than our own parser. It turns out that these builtins
      appear to be @i{slower} than our parser for this benchmark, but they're
      available as the @code{upickle.default.web.read/write} functions or the
      @code{upickle.WebJson} object if you for some reason want to use them.
    @p
      uJson is a fork of Erik Osheim's excellent [Jawn](https://github.com/non/jawn)
      JSON library, and inherits a lot of it's performance from Erik's work.

  @sect{Version History}
    @sect{0.6.5}
      @ul
        @li
          Add ability to update a JSON dictionary key or array item in place
          via @hl.scala{json(0)("myFieldA") = _.num + 100}
    @sect{0.6.4}
      @ul
        @li
          Fix uJson direct dependency artifact naming
    @sect{0.6.3}
      @ul
        @li
          Added @code{ujson.copy} helper
        @li
          Added implicit constructors for @code{ujson.Js.Obj} and @code{Arr}
    @sect{0.6.2}
      @ul
        @li
          Fix conversion of case classes to other case classes via upickle.default.transform
    @sect{0.6.0}
      @ul
        @li
          ~3x faster than 0.5.1; uPickle now has the best @sect.ref{Performance}
          out of any of the commonly-used Scala JSON libraries

        @li
          The old @code{upickle.Js} JSON AST and @lnk("non/jawn", "https://github.com/non/jawn")
          dependency have been combined into the @sect.ref{uJson} standalone library.
          uJson provides high-performance streaming JSON processing that lets uPickle
          parse input strings directly to case classes without an intermediate AST.
        @li
          @code{upickle.Js} objects are now mutable, and had some implicits added
          to make @sect.ref{Construction} less awkward.
        @li
          The set of @sect.ref{Common Operations} and @sect.ref{JSON Utilities}
          has been fleshed out: you now have convenient helpers for streaming
          JSON re-formatting or validation, and can read from arbitrary inputs
          (strings, byte-arrays, files, ...) using the same @code{upickle.default.read}
          call
        @li
          The way you write @sect.ref{Custom Picklers} and @sect.ref{Custom Configuration}
          has changed. The new ways are hopefully more intuitive,
          allow much better back-end performance, and should be just as flexible
          as the old way, but if you have custom picklers/configurations in your
          code you'll have to go update them.
        @li
          uPickle now supports parsing to (and serializing) @sect.ref{Other ASTs},
          from libraries such as Circe, Argonaut, Json4s or Play-Json. You can now
          also do high-performance/streaming @sect.ref{Cross-Library Conversions}
          to transform from one library's AST to another without any intermediate
          structures.

    @sect{0.5.1}
      @ul
        @li
          Strip out automatic "deep" case-class serialization: you must now
          define a serializer for each case class you want to deal with, preferably
          in the companion object
        @li
          Upgrade Jawn version to 0.11.0, add helpers in @code{ujson} to
          parse JSON coming from files.
        @li
          New @code{ujson.writeTo} function for serializing JSON directly
          to a @code{java.io.Writer}, rather than creating a @code{String}

        @li
          @code{ujson.write} now takes an optional `sortKeys` flag, if
          you want the JSON dictionaries to rendered in a standardized order

        @li
          Drop support fo Scala 2.10

    @sect{0.4.3}
      @ul
        @li
          Support for @hl.scala{BigInt} and @hl.scala{BigDecimal},
          thanks to @lnk("Jisoo Park", "https://github.com/guersam")
        @li
          @code{Js.Value}s are now serializable, thanks to
          @lnk("Felix Dietze", "https://github.com/fdietze")
        @li
          Made it easy to write @sect.ref{Manual Sealed Trait Picklers}
          in order to work around problems with SI-7046
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.2")
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.1")
    @sect{0.4.0}
      @ul
        @li
          Allow custom handling for JSON @hl.scala{null}s via a @sect.ref{Custom Configuration}
        @li
          Made @hl.scala{upickle.key} a @hl.scala{case class}
        @li
          Remove unnecessary dependency of @hl.scala{derive} on default arguments #143
        @li
          Fixed derivation allowing Caching Picklers in a @hl.scala{case class}'s companion object, potentially speeding up compilation times and runtimes
    @sect{0.3.9}
      @ul
        @li
          Add @hl.scala{.arr: Seq[Js.Value]}, @hl.scala{.obj: Map[String, Js.Value]}, @hl.scala{.str: String} and @hl.scala{.num: Double} helper methods on @hl.scala{Js.Value} to simplify usage as a simple JSON tree.
        @li
          @hl.scala{Invalid.Json} and @hl.scala{Invalid.Data} now have better exception messages by default, which should simplify debugging
        @li
          Some usages should compile faster due to fiddling with implicits (#138)
    @sect{0.3.8}
      @ul
        @li
          Tweaks to PPrint
    @sect{0.3.7}
      @ul
        @li
          You can now pass in an @hl.scala{indent} parameter to @hl.scala{upickle.default.write} in order to format/indent the JSON nicely across multiple lines
        @li
          Derivation based on sealed abstract classes works, in addition to traits (#104), thanks to @a("Voltir", href:="https://github.com/Voltir")
        @li
          Fix non-deterministic failure due to improperly implemented @code{equals}/@code{hashCode} in macro (#124), thanks to @a("Voltir", href:="https://github.com/lihaoyi/upickle-pprint/issues/124")
        @li
          Slightly improve hygiene of uPickle/PPrint macro expansion
        @li
          uPickle de-serialization failures should no longer throw @code{MatchErrors} (#101)
        @li
          Using case-class-derived @code{Reader}s/@code{Writer}s should no longer fail in class @code{extends} clauses (#108)
        @li
          @code{Float.NaN} and @code{Double.NaN} are now properly handled (#123)
        @li
          Provided an example of a @sect.ref{Custom Configuration} being used to @code{snake_case} case-class fields during serialization/de-serialization (#120)

    @sect{0.3.6}
      @ul
        @li
          Fix more bugs in PPrint derivation
    @sect{0.3.5}
      @ul
        @li
          Fix some bugs in PPrint derivation
    @sect{0.3.4}
      @ul
        @li
          Remove unnecessary shapeless dependency
    @sect{0.3.3}
      @ul
        @li
          Fix more edge cases to avoid diverging implicits
    @sect{0.3.2}
      @ul
        @li
          Fix more edge cases around typeclass derivation: #94, #95, #96
        @li
          Don't get tripped up by custom Apply methods: #48
    @sect{0.3.1}
      @ul
        @li
          Fixed edge cases around typeclass derivation

    @sect{0.3.0}
      @ul
        @li
          Top-to-bottom rewrite of type-class derivation macros. Much faster, more reliable, etc.. Still one or two cases where it misbehaves, but much fewer than before. Extracted it into the @hl.scala{derive} subproject
        @li
          Force users to choose between @hl.scala{import upickle.default._} which now renders sealed trait hierarchies as dictionaries with a @hl.scala{$type} attribute, and @hl.scala{import upickle.legacy._} which does the old-style array-wrapper.
        @li
          You can also now create your own custom subclass of @hl.scala{upickle.Api} if you wish to customize things further, e.g. changing the type-attribute or changing the rendering of case classes.

    @sect{0.2.8}
      @ul
        @li
          Support for @hl.scala{java.util.UUID}, which are serialized as strings in the standard format

    @sect{0.2.7}
      @ul
        @li
          Re-published for Scala.js 0.6.1

    @sect{0.2.6}
      @ul
        @li
          @hl.scala{'Symbol}s are now read/write-able by default
        @li
          Added lots of warnings for common issues
        @li
          @hl.scala{Map[String, V]} now pickles to a JSON dictionary @hl.scala(""""key": "value", ...}"""). @hl.scala{Map[K, V]} for all other @hl.scala{K != String} are unchanged
        @li
          Source maps now point towards a reasonabel place on Github


    @sect{0.2.5}
      @ul
        @li
          Fixed [#23](https://github.com/lihaoyi/upickle/issues/23): self-recursive data structures are now supported.
        @li
          Fixed [#18](https://github.com/lihaoyi/upickle/issues/18): you can now auto-pickle classes in objects that originated from traits that were mixed in.


    @sect{0.2.4}
      @ul
        @li
          Support reading and writing @hl.scala{null}
        @li
          Fixed Reader/Writer macros for single-class sealed hierarchies
        @li
          Used @hl.scala{CanBuildFrom} to serialize a broader range of collections

    @sect{0.2.3}
      @ul
        @li
          Added a pickler for @hl.scala{Unit}/@hl.scala{()}

    @sect{0.2.2}
      @ul
        @li
          Swapped over from the hand-rolled parser to using @hl.scala{Jawn}/@hl.scala{JSON.parse} on the two platforms, resulting in a 10-15x speedup for JSON handling.
        @li
          Renamed @hl.scala("""Js.{String, Object, Array, Number}""") into @hl.scala("""Js.{Str, Obj, Arr, Num}"""), and made @hl.scala{Js.Arr} and @hl.scala{Js.Obj} use varargs, to allow for better direct-use.
        @li
          Documented and exposed JSON API for direct use by users of the library.

    @sect{0.2.1}
      @ul
        @li
          Improved error messages for unpickle-able types
        @li
          ScalaJS version now built against 0.5.3

    @sect{0.2.0}
      @ul
        @li
          Members of sealed trait/class hierarchies are now keyed with the fully-qualified name of their class, rather than an index, as it is less likely to change due to adding or removing classes
        @li
          Members of sealed hierarchies and parameters now support a @hl.scala{upickle.key("...")} annotation, which allows you to override the default key used (which is the class/parameter name) with a custom one, allowing you to change the class/param name in your code while maintaining compatibility with serialized structures
        @li
          Default parameters are now supported: they are used to substitute missing keys when reading, and cause the key/value pair to be omitted if the serialized value matches the default when writing
        @li
          Missing keys when deserializing case classes now throws a proper @hl.scala{Invalid.Data} exception
        @li
          @hl.scala{object}s are now serialized as @hl.scala("""{}""") rather than @hl.scala{[]}, better matching the style of case classes
        @li
          0-argument case classes, previously unsupported, now serialize to @hl.scala("""{}""") the same way as @hl.scala{object}s
        @li
          Fixed a bug that was preventing multi-level sealed class hierarchies from being serialized due to a compilation error
        @li
         Fixed a bug causing case classes nested in other packages/objects and referred to by their qualified paths to fail pickling
        @li
          Tightened up error handling semantics, swapping out several @hl.scala{MatchError}s with @hl.scala{Invalid.Data} errors

    @sect{0.1.7}
      @ul
        @li
          Cleaned up the external API, marking lots of things which should have been private private or stuffing them in the @hl.scala{Internals} namespace
        @li
          Organized things such that only a single import @hl.scala{import upickle._} is necessary to use the library

    @sect{0.1.6}
      @ul
        @li
          Tuples and case classes now have implicit picklers up to an arity limit of 22.
        @li
          Case classes now serialize as JSON dictionaries rather than as lists.

    @sect{0.1.5}
      @ul
        @li
          Simple case classes and case class hierarchies are now auto-serializable view Macros. No need to define your own implicit using @hl.scala{Case0ReadWriter} anymore!

    @sect{0.1.4}
      @ul
        @li
          Serialize numbers as JSON numbers instead of Strings.

    @sect{0.1.3}
      @ul
        @li

          Specification of the exception-throwing behavior: instead of failing with random @hl.scala{MatchError}s or similar, parse failures now are restricted to subclasses @hl.scala{upickle.Invalid} which define different failure modes.
